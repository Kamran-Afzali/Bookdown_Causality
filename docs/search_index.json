[["index.html", "Causal Inference in R Chapter 1 Foundations of Causal Statistical Analysis 1.1 Introduction 1.2 Summary Table: Techniques for Causal Statistical Analysis 1.3 Methodological Deep Dive with Practical Guidance 1.4 Discussion 1.5 References", " Causal Inference in R Kamran Afzali 2025-07-22 Chapter 1 Foundations of Causal Statistical Analysis 1.1 Introduction Understanding causality is one of the most enduring and fundamental challenges in science. Across disciplines—from public health and economics to education, neuroscience, and artificial intelligence—researchers are increasingly tasked not only with identifying patterns in data but with uncovering the mechanisms that generate them. While traditional statistical analysis excels at quantifying associations, scientific inquiry often aims at a deeper ambition: to infer causal relationships—to determine what would happen under specific interventions, policies, or changes to a system. The distinction between correlation and causation is more than a methodological nuance; it defines the boundary between description and explanation, and between prediction and control. This essay serves as the first in a multi-part series on the foundations of causal statistical analysis. It provides a panoramic overview of the most widely used techniques for estimating causal effects, each grounded in distinct theoretical frameworks and operational assumptions. These methods span randomized controlled trials (RCTs), which serve as the epistemic gold standard, to a wide range of quasi-experimental and model-based approaches developed to address the limitations of real-world data. In practice, researchers must often navigate data landscapes in which randomization is infeasible, treatment selection is endogenous, and temporal or structural confounding is ubiquitous. This is where modern causal inference techniques offer essential tools—not only for estimating effects, but for interrogating the validity of those estimates. At the heart of this endeavor lies a tension between identifiability and assumptions. Every causal method rests on a set of assumptions—about how the data were generated, how variables relate, and what sources of bias are controlled or ignored. While some methods emphasize robustness through design (e.g., difference-in-differences, regression discontinuity, or instrumental variables), others attempt to model the data-generating process explicitly, drawing from structural modeling, counterfactual reasoning, or machine learning. Each method is powerful under the right conditions and misleading when applied uncritically. This underscores a central theme of the series: there is no universally “best” method for causal inference. Rather, the suitability of each technique depends on the scientific question, data structure, and the plausibility of underlying assumptions. To guide practitioners in this complex terrain, we begin with a comparative summary table outlining the assumptions, strengths, limitations, and implementation tools for each technique. This table is not merely a catalog—it is a scaffold for deeper engagement. Subsequent posts in the series will explore each method in detail, presenting both theoretical foundations and practical workflows using open-source statistical packages in R and Python. These installments will include visualizations, diagnostics, sensitivity analyses, and real-world case studies drawn from public health, education, and policy evaluation. Causal analysis is both an art and a science: it demands careful reasoning, domain knowledge, and transparent methodology. As the demand for evidence-based decision-making grows—particularly in the age of big data and algorithmic governance—causal inference provides a principled framework for moving from data to action. This series is designed to empower readers to approach causal questions rigorously, critically, and creatively. 1.2 Summary Table: Techniques for Causal Statistical Analysis Technique Key Assumptions Use Cases Strengths Limitations Tools/Packages Randomized Controlled Trials (RCTs) Random assignment ensures exchangeability Clinical trials, A/B testing Eliminates confounding Often infeasible or unethical randomizr (R), DoWhy (Py) Regression Adjustment No unmeasured confounders, correct model Policy, health outcomes Simple, widely used Sensitive to omitted variables, model misspecification lm(), glm() (R), statsmodels, sklearn (Py) Propensity Score Matching (PSM) Conditional independence given observed covariates Observational studies Balances covariates, intuitive Sensitive to unmeasured confounding, poor overlap MatchIt, twang (R), DoWhy, causalml (Py) Inverse Probability Weighting (IPW) Correct treatment model, positivity Longitudinal data Handles time-varying confounding Can produce unstable weights ipw, survey (R), zEpid (Py) Difference-in-Differences (DiD) Parallel trends Policy reforms, natural experiments Controls for unobserved time-invariant confounders Vulnerable if trends diverge fixest, did (R), linearmodels (Py) Instrumental Variables (IV) Relevance, exclusion restriction Endogeneity correction Addresses unmeasured confounding Finding valid instruments is hard ivreg, AER (R), linearmodels.iv (Py) Regression Discontinuity (RDD) Sharp cutoff, local randomization Education, policy thresholds Transparent identification Limited to local effect near cutoff rdrobust, rddtools (R), rdd, statsmodels (Py) Causal Forests Unconfoundedness, heterogeneity Precision medicine, targeting Captures treatment heterogeneity Requires large data, unmeasured confounding risk grf, causalTree (R), econml, causalml (Py) Bayesian Structural Time Series (BSTS) No unmeasured confounders post-intervention Time series interventions Handles complex time trends Sensitive to model/priors CausalImpact, bsts (R), tfcausalimpact (Py) Targeted Maximum Likelihood Estimation (TMLE) Double robustness Epidemiology, observational data Robust, ML integration Computationally intensive tmle, ltmle (R), zepid (Py) G-Computation No unmeasured confounding, correct model Mediation, marginal effects Flexible, counterfactuals Model dependence gfoRmula, ltmle (R), zepid (Py) Structural Equation Modeling (SEM) Correct structure, no unmeasured confounding Latent variables, mediation Models complex relationships Requires strong assumptions lava RESOLVED: lavaan (R), semopy, pysem (Py) Directed Acyclic Graphs (DAGs) Causal sufficiency, accurate knowledge Study design, confounder control Clarifies assumptions Not an estimation method dagitty, ggdag (R), causalgraphicalmodels (Py) Double Machine Learning (DML) Frameworks Conditional ignorability, consistent nuisance estimation High-dimensional observational studies Robust to model misspecification, handles high-dimensional confounders Requires large data, assumes no unmeasured confounding DoubleML (R), econml, causalml (Py) 1.3 Methodological Deep Dive with Practical Guidance Randomized Controlled Trials (RCTs) RCTs are the gold standard for causal inference. Random assignment neutralizes confounding, ensuring internal validity. However, practical, ethical, or financial constraints often limit their feasibility. When viable, they deliver the most credible causal estimates. Regression Adjustment This method models the outcome as a function of treatment and covariates. While easy to implement, it assumes no unmeasured confounding and correct model specification. It’s essential to examine covariate balance and conduct robustness checks. Propensity Score Matching (PSM) PSM aims to mimic randomization by matching units with similar probabilities of treatment. It balances covariates well but fails under unmeasured confounding. Diagnostic tools like balance plots are crucial. Inverse Probability Weighting (IPW) IPW reweights samples to simulate random assignment. It handles time-varying confounding but can produce unstable weights, requiring trimming or stabilization. It’s powerful for longitudinal and panel data. Difference-in-Differences (DiD) DiD compares treated and control units over time, assuming parallel trends. It is popular for evaluating policy interventions but sensitive to trend violations. Visualizing pre-treatment trends and using placebo tests enhance credibility. Instrumental Variables (IV) IV methods handle endogeneity by using external variables that affect treatment but not the outcome directly. The approach hinges on the strength and validity of instruments—criteria that are difficult to verify. Regression Discontinuity Design (RDD) RDD exploits sharp cutoffs for treatment assignment. It provides quasi-experimental validity but estimates only local effects near the threshold. Validity depends on smoothness and non-manipulation at the cutoff. Causal Forests Causal forests extend random forests to estimate heterogeneous treatment effects. They are ideal for personalized interventions but require large datasets and are vulnerable to omitted confounding. Bayesian Structural Time Series (BSTS) BSTS combines state-space models with Bayesian inference to estimate intervention effects in time series. It accommodates trend and seasonality but is sensitive to model misspecification and prior choices. Targeted Maximum Likelihood Estimation (TMLE) TMLE integrates machine learning into causal effect estimation. It provides double robustness and efficient inference under complex data settings but can be computationally demanding. G-Computation G-computation models potential outcomes under each treatment. It is flexible and counterfactual-based but requires accurate modeling and complete covariate adjustment. Structural Equation Modeling (SEM) SEM enables the modeling of complex causal structures, including latent constructs and mediation. Its interpretability is appealing but hinges on correct model specification and the absence of unmeasured confounding. Directed Acyclic Graphs (DAGs) DAGs are essential for clarifying causal assumptions. While not an estimation method, they guide design and analysis by identifying confounders, mediators, and colliders. 1.4 Discussion The comparative framework presented in this foundational overview highlights both the diversity and the interdependence of causal inference techniques. A central takeaway is that no single method guarantees valid causal inference in all contexts. Rather, the validity of any technique depends critically on whether its assumptions align with the structure of the data and the theoretical understanding of the system under study. This observation has two key implications for applied researchers. First, triangulation—the use of multiple methods to approach the same causal question—is not only desirable but often necessary. For instance, one might use propensity score matching to achieve covariate balance, regression adjustment to model outcome differences, and then compare results with those from a targeted maximum likelihood estimation (TMLE) approach. If conclusions converge, confidence in causal interpretation increases. If not, divergences can reveal sensitivity to assumptions such as model specification or unmeasured confounding. Thus, causal inference is inherently iterative, requiring both methodological flexibility and diagnostic rigor. Second, methodological literacy is not enough; researchers must also cultivate causal reasoning. Directed Acyclic Graphs (DAGs), while not themselves estimators, play a vital role in clarifying which variables to control for and which paths to block or preserve. DAG-based thinking helps researchers navigate common pitfalls such as controlling for colliders or mediators, both of which can induce bias. The thoughtful use of DAGs, therefore, bridges qualitative theoretical insight with quantitative estimation. Another tension arises between interpretability and complexity. Classical techniques like regression or instrumental variables are often preferred for their clarity and theoretical grounding, while modern approaches such as causal forests and TMLE offer increased flexibility and robustness in high-dimensional or non-linear settings. However, these gains often come at the cost of interpretability, especially for stakeholders or policy-makers who require transparent causal narratives. This raises an important trade-off: when should we prioritize explainability over precision, and how do we communicate these decisions to interdisciplinary audiences? In addition, the growing use of machine learning in causal inference—exemplified by methods like causal forests and TMLE—requires new standards for validation and transparency. Unlike predictive modeling, causal questions are inherently counterfactual and cannot be validated through conventional cross-validation. Techniques such as falsification tests, placebo analyses, and sensitivity analyses become indispensable, particularly when machine learning models are involved. Finally, equity and ethics must be central to causal analysis, especially in domains like public health, criminal justice, and education. Methods that adjust for observed variables can inadvertently perpetuate structural inequalities if those variables are themselves proxies for systemic bias. Researchers must therefore engage critically with both the data and the social contexts from which they arise, treating causal models not just as statistical tools but as ethical instruments. The subsequent posts in this series will explore each technique in depth, including code implementation, diagnostic strategies, and real-world case studies. By weaving together statistical rigor, domain expertise, and ethical reflexivity, we aim to equip researchers with a robust and responsible causal toolkit. 1.5 References Hernán &amp; Robins (2020). Causal Inference: What If. Pearl, Glymour, &amp; Jewell (2016). Causal Inference in Statistics: A Primer. VanderWeele (2015). Explanation in Causal Inference. Causal AI Blog by Judea Pearl: https://causality.cs.ucla.edu/blog/ Netflix Tech Blog on Causal Inference: https://netflixtechblog.com/computational-causal-inference-at-netflix-293591691c62 Number Analytics Education Series: https://www.numberanalytics.com/blog/ "],["causal-inference-in-practice-i-randomized-controlled-trials-and-regression-adjustment.html", "Chapter 2 Causal Inference in Practice I: Randomized Controlled Trials and Regression Adjustment 2.1 Introduction 2.2 1. Randomized Controlled Trials: Design and Analysis 2.3 2. Regression Adjustment: A Model-Based Approach to Causal Inference 2.4 Toward Integrated Reasoning 2.5 Conclusion", " Chapter 2 Causal Inference in Practice I: Randomized Controlled Trials and Regression Adjustment 2.1 Introduction In the first post of this series, we presented a comprehensive overview of key causal inference methods, highlighting the assumptions, strengths, and limitations that distinguish each technique. In this follow-up post, we delve into the two most foundational approaches: Randomized Controlled Trials (RCTs) and Regression Adjustment. Although these methods differ in their reliance on data-generating processes and assumptions, both provide crucial entry points into the logic of causal reasoning. This essay offers a theoretically grounded and practically oriented treatment of each method, including code implementation in R, diagnostics, and interpretive guidance. RCTs represent the epistemic benchmark for causal inference, often described as the “gold standard” due to their unique ability to eliminate confounding through randomization. Regression Adjustment, by contrast, models the outcome conditional on treatment and covariates, requiring more assumptions but offering wide applicability in observational settings. Despite their differences, both approaches are underpinned by counterfactual reasoning—the idea that causal effects reflect the difference between what actually happened and what would have happened under a different treatment assignment. Understanding the logic and implementation of these two methods is essential not only for their direct use but also because they serve as the conceptual and statistical scaffolding for more complex techniques such as matching, weighting, and doubly robust estimators. 2.2 1. Randomized Controlled Trials: Design and Analysis 2.2.1 Theoretical Foundations In an RCT, participants are randomly assigned to treatment or control groups. This process ensures that, on average, both groups are statistically equivalent on all covariates, observed and unobserved. The core assumption is exchangeability—that the potential outcomes are independent of treatment assignment conditional on randomization. This enables simple comparisons of mean outcomes across groups to yield unbiased estimates of causal effects. Formally, let \\(Y(1)\\) and \\(Y(0)\\) denote the potential outcomes under treatment and control, respectively. The average treatment effect (ATE) is defined as: \\[ \\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] \\] In a perfectly randomized trial, we estimate the ATE by comparing the sample means: \\[ \\widehat{\\text{ATE}} = \\bar{Y}_1 - \\bar{Y}_0 \\] This estimator is unbiased and consistent, provided randomization is successfully implemented and compliance is perfect. 2.2.2 R Implementation Let’s simulate a simple RCT to estimate the effect of a binary treatment on an outcome. # Load necessary libraries library(tidyverse) # Set seed for reproducibility set.seed(123) # Simulate data n &lt;- 1000 data_rct &lt;- tibble( treatment = rbinom(n, 1, 0.5), outcome = 5 + 2 * treatment + rnorm(n) ) # Estimate ATE using difference in means ate_estimate &lt;- data_rct %&gt;% group_by(treatment) %&gt;% summarise(mean_outcome = mean(outcome)) %&gt;% summarise(ATE = diff(mean_outcome)) print(ate_estimate) 2.2.3 Model-Based Inference While RCTs do not require model-based adjustments, regression models are often used to improve precision or adjust for residual imbalances. In the RCT context, such models are descriptive rather than corrective. # Linear regression with treatment as predictor lm_rct &lt;- lm(outcome ~ treatment, data = data_rct) summary(lm_rct) The coefficient on the treatment variable in this model provides an estimate of the ATE. Importantly, in randomized designs, the inclusion of additional covariates should not substantially alter the point estimate, though it may reduce variance. 2.2.4 Diagnostics and Integrity Although randomization ensures internal validity, its practical implementation must be verified. Balance diagnostics, such as standardized mean differences or visualizations of covariate distributions by treatment group, help ensure that the groups are equivalent at baseline. If substantial imbalances exist, especially in small samples, model-based covariate adjustment can improve efficiency but not eliminate bias due to poor randomization. 2.3 2. Regression Adjustment: A Model-Based Approach to Causal Inference 2.3.1 Conceptual Overview Regression Adjustment, sometimes called covariate adjustment, is one of the most widely used methods for causal estimation in observational studies. Unlike RCTs, this approach requires the assumption of no unmeasured confounding, often called conditional ignorability: \\[ Y(1), Y(0) \\perp D \\mid X \\] Here, \\(D\\) is the binary treatment variable and \\(X\\) is a vector of observed covariates. The central idea is to control for confounders \\(X\\) that affect both treatment assignment and potential outcomes. The linear model typically takes the form: \\[ Y = \\beta_0 + \\beta_1 D + \\beta_2 X + \\varepsilon \\] The coefficient \\(\\beta_1\\) is interpreted as the average treatment effect, assuming the model is correctly specified and all relevant confounders are included. 2.3.2 R Implementation We now simulate observational data with a confounder to demonstrate regression adjustment. # Simulate observational data set.seed(123) n &lt;- 1000 x &lt;- rnorm(n) d &lt;- rbinom(n, 1, plogis(0.5 * x)) y &lt;- 5 + 2 * d + 1.5 * x + rnorm(n) data_obs &lt;- tibble( treatment = d, covariate = x, outcome = y ) # Naive model (without adjustment) lm_naive &lt;- lm(outcome ~ treatment, data = data_obs) summary(lm_naive) # Adjusted model lm_adjusted &lt;- lm(outcome ~ treatment + covariate, data = data_obs) summary(lm_adjusted) The naive model, which omits the confounder, yields a biased estimate of the treatment effect. By contrast, the adjusted model corrects this bias, provided all relevant confounders are included and the functional form is correct. 2.3.3 Limitations and Diagnostics Regression Adjustment hinges on correct model specification and the inclusion of all relevant confounders. Omitted variable bias remains a major threat, and multicollinearity or misspecified functional forms can distort estimates. Residual plots, variance inflation factors, and specification tests are essential for model diagnostics. Moreover, regression does not address overlap—the requirement that all units have a non-zero probability of receiving each treatment conditional on covariates. Violations of this assumption can lead to extrapolation and poor generalizability. One strategy to assess covariate overlap is to model the propensity score and visualize its distribution across treatment groups. # Estimate propensity scores ps_model &lt;- glm(treatment ~ covariate, data = data_obs, family = binomial()) data_obs &lt;- data_obs %&gt;% mutate(pscore = predict(ps_model, type = &quot;response&quot;)) # Plot propensity scores ggplot(data_obs, aes(x = pscore, fill = factor(treatment))) + geom_density(alpha = 0.5) + labs(fill = &quot;Treatment Group&quot;, title = &quot;Propensity Score Overlap&quot;) If there is poor overlap between groups, regression adjustment may yield estimates with high variance and questionable validity. 2.3.4 Causal Interpretation While regression models provide estimates of conditional treatment effects, care must be taken in interpreting these coefficients causally. The treatment effect estimated by regression adjustment is unbiased only under strong assumptions: no unmeasured confounding, correct model specification, and sufficient overlap. This makes regression adjustment a double-edged sword. Its ease of use and interpretability make it appealing, but its susceptibility to hidden bias requires rigorous scrutiny. 2.4 Toward Integrated Reasoning The juxtaposition of RCTs and regression adjustment highlights the contrast between design-based and model-based inference. RCTs achieve causal identification through the randomization mechanism itself, rendering statistical adjustment unnecessary (but sometimes helpful for precision). Regression adjustment, on the other hand, relies entirely on the plausibility of its assumptions, making it vulnerable to hidden confounding and specification errors. Importantly, these methods should not be viewed in isolation. Hybrid designs and analytic strategies—such as regression adjustment in RCTs or design-based diagnostics in observational studies—blur the boundaries and point toward more integrated approaches to causal inference. Furthermore, emerging methods such as doubly robust estimation, propensity score weighting, and machine learning–based causal estimators build upon the foundations established by these two methods. Understanding the mechanics and logic of RCTs and regression adjustment is thus a prerequisite for mastering more advanced techniques. 2.5 Conclusion In this installment, we explored the theoretical rationale, implementation, and practical considerations of two cornerstone methods in causal inference: Randomized Controlled Trials and Regression Adjustment. RCTs provide unmatched causal credibility when feasible, while regression models offer flexible tools for analyzing observational data under strong assumptions. Their complementary roles in the causal inference toolkit make them indispensable for any applied researcher. The next entry in this series will turn to Propensity Score Methods, where we will examine how matching and weighting strategies seek to approximate randomized experiments using observational data. As with all causal methods, the key lies not just in computation, but in the clarity of assumptions and the integrity of reasoning. By combining design principles, diagnostic rigor, and ethical sensitivity, causal inference offers a powerful framework for navigating the complexity of real-world data. "],["causal-inference-in-practice-ii-propensity-scores-doubly-robust-estimators-and-inverse-probability-weighting.html", "Chapter 3 Causal Inference in Practice II: Propensity Scores, Doubly Robust Estimators, and Inverse Probability Weighting 3.1 Propensity Score Methods 3.2 Inverse Probability Weighting (IPW) 3.3 Doubly Robust Estimators 3.4 Integrative Interpretation 3.5 Summary Table 3.6 Conclusion 3.7 References", " Chapter 3 Causal Inference in Practice II: Propensity Scores, Doubly Robust Estimators, and Inverse Probability Weighting The previous post investigated the foundations of Randomized Controlled Trials and Regression Adjustment. In real-world observational data, achieving balance on covariates is challenging, and simple regression models rely heavily on conditional independence and correct model specification. Propensity score–based methods, including matching, Inverse Probability Weighting (IPW), and doubly robust estimation, offer suitable alternatives. These methods alleviate some assumptions but introduce others such as positivity and model correctness. In this essay, we articulate their theoretical motivations, derive formal estimators, and demonstrate implementation in R. 3.1 Propensity Score Methods Propensity score methods serve to emulate a randomized trial by balancing observed confounders across treatment groups. The propensity score \\(e(x) = P(D=1 \\mid X=x)\\) compresses multivariate covariate information into a single scalar. Under the assumption of conditional ignorability (\\(Y(1),Y(0) \\perp D \\mid X\\)) and overlap (\\(0 &lt; e(x) &lt; 1\\)), adjusting for \\(e(x)\\) suffices to remove bias due to observed covariates. Formally, denote the propensity score–adjusted estimator: \\[ \\widehat{\\text{ATE}} = \\frac{1}{n} \\sum_{i=1}^n \\left( \\frac{D_i Y_i}{\\hat e(X_i)} - \\frac{(1-D_i)Y_i}{1 - \\hat e(X_i)} \\right). \\] In practice, one normally models \\(e(x)\\) with logistic regression: library(tidyverse) set.seed(42) n &lt;- 2000 x1 &lt;- rnorm(n) x2 &lt;- rbinom(n,1,0.3) e &lt;- plogis(-0.5 + 0.8 * x1 - 0.4 * x2) d &lt;- rbinom(n,1,e) y &lt;- 3 + 2 * d + 1.2 * x1 - 0.5 * x2 + rnorm(n) data &lt;- tibble(x1, x2, treatment = d, outcome = y) ps_model &lt;- glm(treatment ~ x1 + x2, data = data, family = binomial) data &lt;- data %&gt;% mutate(pscore = predict(ps_model, type = &quot;response&quot;)) ggplot(data, aes(x = pscore, color = factor(treatment))) + geom_density() + labs(title = &quot;Propensity Score by Treatment Group&quot;) To estimate ATE by matching: library(MatchIt) match_out &lt;- matchit(treatment ~ x1 + x2, data = data, method = &quot;nearest&quot;, ratio = 1) matched &lt;- match.data(match_out) lm_matched &lt;- lm(outcome ~ treatment, data = matched) summary(lm_matched) lm_non_matched &lt;- lm(outcome ~ treatment, data = data) summary(lm_non_matched) plot(match_out, type = &quot;qq&quot;, interactive = FALSE) Here, coefficients() for treatment gives the ATE among matched units, interpretable under the assumption of balance on \\(X\\). Diagnostics should include covariate balance checks after matching (e.g., plot(match_out, type=\"jitter\")). 3.2 Inverse Probability Weighting (IPW) IPW uses propensity score–based weighting to reweight the sample, such that the weighted treated and control groups become exchangeable. Each subject is weighted as: \\[ w_i = \\frac{D_i}{\\hat e(X_i)} + \\frac{1-D_i}{1-\\hat e(X_i)}. \\] Then, \\[ \\widehat{\\text{ATE}}_{\\text{IPW}} = \\frac{\\sum_i w_i Y_i}{\\sum_i w_i}. \\] IPW estimates the ATE without explicit modeling of \\(E[Y \\mid D, X]\\), but hinge critically on correctly specified propensity scores and stable overlap. library(survey) data$wt &lt;- with(data, ifelse(treatment == 1, 1/pscore, 1/(1-pscore))) design &lt;- svydesign(ids = ~1, weights = ~wt, data = data) ipw_mod &lt;- svyglm(outcome ~ treatment, design = design) summary(ipw_mod) The coefficient on treatment gives the IPW-estimated ATE. One must check for extreme weights using summaries (summary(data_obs$wt)) and consider trimming. 3.3 Doubly Robust Estimators Doubly robust estimators combine outcome modeling and propensity weighting so that estimation remains consistent if either model is correctly specified. The canonical form is: \\[ \\widehat{\\text{ATE}}_{\\text{DR}} = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ m_1(X_i) - m_0(X_i) + \\frac{D_i(Y_i - m_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1 - D_i)(Y_i - m_0(X_i))}{1 - \\hat{e}(X_i)} \\right] \\] where \\(\\hat m(D, X)\\) is an estimated regression of outcome on treatment and covariates. om_mod &lt;- lm(outcome ~ treatment + x1 + x2, data = data) data$mu1_hat &lt;- predict(om_mod, newdata = transform(data, treatment = 1)) data$mu0_hat &lt;- predict(om_mod, newdata = transform(data, treatment = 0)) # Doubly robust ATE dr_ate &lt;- with(data, mean((treatment/pscore - (1-treatment)/(1-pscore))*(outcome - (treatment*mu1_hat + (1-treatment)*mu0_hat)) + mu1_hat - mu0_hat)) dr_ate This dr_ate estimate is doubly robust: consistent if either propensity or outcome model is correct. Practical use involves bootstrapping for variance. 3.4 Integrative Interpretation Propensity scores adjust for observed confounders in a manner motivated by design, yielding a pseudo-randomized experiment. IPW pushes this further by weighting, creating a synthetic population. Doubly robust methods guard against misspecification of either the weighting model or the outcome model—ensuring valid ATE estimation under broader conditions. However, each method remains anchored in core assumptions: ignorability, overlap, and model correctness. Diagnostics—such as balance checks after matching/IPW, weight summaries, and residual/outcome-model validation—are essential before causal claims are made. 3.5 Summary Table Method Model Requirement Consistency If Estimator Formula Primary Strength Propensity Score Matching Logistic for \\(e(x)\\) Propensity correctly estimated Difference in means after matching Balances covariates; design mimicry Inverse Probability Weighting (IPW) Logistic for \\(e(x)\\) Propensity correctly estimated Weighted regression or weighted mean difference Creates reweighted, exchangeable sample Doubly Robust Estimator Logistic for \\(e(x)\\) or outcome \\(m(D,X)\\) Either model correctly specified ATE combining weighted residuals and conditional means Robust to misspecification, efficient 3.6 Conclusion This post has advanced our series by exploring methods that bridge the gap between randomization and modeling. Propensity scores, IPW, and doubly robust estimators offer complementary strategies for tackling confounding, each accompanied by unique trade‑offs in terms of assumptions, stability, and interpretability. The next installment will explore Matching, Difference-in-Differences, and Instrumental Variables, offering further depth and methods for complex real-world data. 3.7 References Rosenbaum, P. R., &amp; Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41–55. Robins, J. M., &amp; Rotnitzky, A. (1995). Semiparametric efficiency in multivariate regression models with missing data. Journal of the American Statistical Association, 90(429), 122–129. Bang, H., &amp; Robins, J. M. (2005). Doubly robust estimation in missing data and causal inference models. Biometrics, 61(4), 962–973. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. "],["causal-inference-in-practice-iii-difference-in-differences-with-a-healthcare-application.html", "Chapter 4 Causal Inference in Practice III: Difference-in-Differences with a Healthcare Application 4.1 Introduction 4.2 Difference-in-Differences: Theoretical Framework 4.3 Application: Evaluating a Telemedicine Program in Healthcare 4.4 Limitations and Extensions 4.5 Conclusion 4.6 References", " Chapter 4 Causal Inference in Practice III: Difference-in-Differences with a Healthcare Application 4.1 Introduction In observational studies, where randomized controlled trials are infeasible, causal inference methods like Difference-in-Differences (DiD) provide a robust framework for estimating treatment effects under specific assumptions. DiD is particularly valuable in settings with panel data, where units are observed over time, and some receive a treatment while others do not. By leveraging the temporal structure of data, DiD isolates the causal effect of a treatment by comparing changes in outcomes between treated and control groups over time. This approach is widely used in fields such as economics, public policy, and healthcare to evaluate interventions like policy changes or medical programs. In this post, we focus on DiD, exploring its theoretical foundations, mathematical formalism, and practical implementation. We apply DiD to a realistic healthcare example—evaluating the impact of a telemedicine program on patient outcomes—using R code to demonstrate the methodology. We also discuss diagnostics, limitations, and extensions to ensure robust causal inference. 4.2 Difference-in-Differences: Theoretical Framework 4.2.1 Core Concept DiD estimates the causal effect of a treatment by comparing the change in outcomes over time between a treated group and a control group. The method assumes that, in the absence of treatment, the treated and control groups would follow parallel trends in their outcomes. This assumption allows DiD to account for time-invariant differences between groups and common time trends affecting both groups. 4.2.2 Mathematical Formalism Let’s formalize the DiD framework. For unit \\(i\\) at time \\(t \\in \\{0, 1\\}\\) (pre- and post-treatment), define: \\(Y_{it}\\): Observed outcome for unit \\(i\\) at time \\(t\\). \\(D_i \\in \\{0, 1\\}\\): Treatment indicator (\\(D_i = 1\\) for treated units, \\(D_i = 0\\) for control units). \\(T_t \\in \\{0, 1\\}\\): Time indicator (\\(T_t = 0\\) for pre-treatment, \\(T_t = 1\\) for post-treatment). \\(Y_{it}(1), Y_{it}(0)\\): Potential outcomes under treatment and control, respectively. The causal effect of interest is the average treatment effect on the treated (ATT): \\[ \\text{ATT} = \\mathbb{E}[Y_{i1}(1) - Y_{i1}(0) \\mid D_i = 1] \\] The DiD estimator assumes that the observed outcome can be modeled as: \\[ Y_{it} = \\beta_0 + \\beta_1 D_i + \\beta_2 T_t + \\delta (D_i \\cdot T_t) + \\epsilon_{it} \\] Where: - \\(\\beta_0\\): Baseline outcome for the control group at \\(t = 0\\). - \\(\\beta_1\\): Time-invariant difference between treated and control groups. - \\(\\beta_2\\): Common time trend affecting both groups. - \\(\\delta\\): The DiD estimator, representing the ATT. - \\(\\epsilon_{it}\\): Error term, assumed to have mean zero. The DiD estimator is computed as: \\[ \\widehat{\\text{DiD}} = \\left( \\bar{Y}_{1, \\text{treated}} - \\bar{Y}_{0, \\text{treated}} \\right) - \\left( \\bar{Y}_{1, \\text{control}} - \\bar{Y}_{0, \\text{control}} \\right) \\] Where \\(\\bar{Y}_{t, g}\\) is the mean outcome for group \\(g\\) (treated or control) at time \\(t\\). 4.2.3 Key Assumption: Parallel Trends The validity of DiD hinges on the parallel trends assumption: \\[ \\mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \\mid D_i = 1] = \\mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \\mid D_i = 0] \\] This assumes that, absent treatment, the average change in outcomes for the treated group would equal that of the control group. While this assumption is untestable directly (since \\(Y_{i1}(0)\\) is unobserved for the treated group post-treatment), we can assess its plausibility by examining pre-treatment trends or including covariates to adjust for potential confounders. 4.2.4 Practical Considerations Data Requirements: DiD requires panel data (same units observed over time) or repeated cross-sectional data with clear treatment and control groups. Covariates: Including control variables unaffected by the treatment can improve precision and adjust for time-varying confounders. Diagnostics: Pre-treatment trends should be visualized to assess the parallel trends assumption. Robustness checks, such as placebo tests, can further validate the model. Extensions: DiD can be extended to multiple time periods, staggered treatment adoption, or heterogeneous effects using advanced methods like generalized DiD. 4.3 Application: Evaluating a Telemedicine Program in Healthcare 4.3.1 Scenario Consider a hospital system implementing a telemedicine program in 2024 to improve patient outcomes, such as reducing hospital readmissions for chronic disease patients. The program is rolled out in select clinics (treated group), while others continue standard in-person care (control group). We observe patient outcomes (e.g., 30-day readmission rates) in 2023 (pre-treatment) and 2025 (post-treatment). Using DiD, we estimate the program’s causal effect on readmissions. 4.3.2 Simulated Data We simulate data for 200 clinics (100 treated, 100 control) with readmission rates over two years. The true treatment effect is a 3% reduction in readmissions. We include a covariate (average patient age) to account for potential confounding. 4.3.3 R Implementation Below is the R code to simulate the data, estimate the DiD effect, and perform diagnostics. # Load required packages library(ggplot2) library(dplyr) # Set seed for reproducibility set.seed(123) # Parameters n_clinics &lt;- 200 # 100 treated, 100 control time_periods &lt;- 2 # 2023 (pre), 2025 (post) true_effect &lt;- -5 # Increased effect size to -5% for stronger impact noise_sd &lt;- 0.5 # Reduced noise to make effect more detectable # Create data data &lt;- data.frame( clinic = rep(1:n_clinics, each = time_periods), time = rep(c(0, 1), times = n_clinics), # 0 = 2023, 1 = 2025 year = rep(c(2023, 2025), times = n_clinics), treated = rep(rep(c(0, 1), each = time_periods), times = n_clinics/2), age = rep(rnorm(n_clinics, mean = 65, sd = 5), each = time_periods) ) # Generate readmission rates (%) data$readmission &lt;- 20 + # Baseline readmission rate 1 * data$treated + # Treated clinics have higher baseline 2 * data$time + # Secular trend true_effect * data$treated * data$time + # Stronger treatment effect 0.1 * data$age + # Age effect rnorm(nrow(data), mean = 0, sd = noise_sd) # Reduced noise # Preview data head(data) # Check parallel trends: Pre-treatment data (2021-2023) data_pre &lt;- data.frame( clinic = rep(1:n_clinics, each = 3), year = rep(c(2021, 2022, 2023), times = n_clinics), treated = rep(rep(c(0, 1), each = 3), times = n_clinics/2), readmission = 20 + 1 * rep(rep(c(0, 1), each = 3), times = n_clinics/2) + # Group effect 2 * rep(0:2, times = n_clinics) + # Linear trend rnorm(3 * n_clinics, 0, noise_sd) # Reduced noise ) # Aggregate means for pre-treatment plot means_pre &lt;- data_pre %&gt;% group_by(year, treated) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) # Plot pre-treatment trends ggplot(means_pre, aes(x = year, y = readmission, color = factor(treated), group = treated)) + geom_line(size = 1) + geom_point(size = 2) + labs(title = &quot;Pre-Treatment Trends in Readmission Rates&quot;, x = &quot;Year&quot;, y = &quot;Readmission Rate (%)&quot;, color = &quot;Group&quot;) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;)) + theme_minimal() # Post-treatment trends for visualization means_post &lt;- data %&gt;% group_by(year, treated) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) # Plot post-treatment trends to show diverging slopes ggplot(means_post, aes(x = year, y = readmission, color = factor(treated), group = treated)) + geom_line(size = 1) + geom_point(size = 2) + labs(title = &quot;Post-Treatment Trends in Readmission Rates&quot;, x = &quot;Year&quot;, y = &quot;Readmission Rate (%)&quot;, color = &quot;Group&quot;) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;)) + theme_minimal() # DiD regression with covariate did_model &lt;- lm(readmission ~ treated + time + treated:time + age, data = data) # Summary of results summary(did_model) # Manual DiD calculation means &lt;- data %&gt;% group_by(treated, time) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) y0_control &lt;- means$readmission[means$treated == 0 &amp; means$time == 0] y1_control &lt;- means$readmission[means$treated == 0 &amp; means$time == 1] y0_treated &lt;- means$readmission[means$treated == 1 &amp; means$time == 0] y1_treated &lt;- means$readmission[means$treated == 1 &amp; means$time == 1] did_estimate &lt;- (y1_treated - y0_treated) - (y1_control - y0_control) cat(&quot;DiD Estimate:&quot;, did_estimate, &quot;%\\n&quot;) # Placebo test: Pre-treatment periods (2022 vs. 2023) data_placebo &lt;- data_pre[data_pre$year %in% c(2022, 2023), ] did_placebo &lt;- lm(readmission ~ treated * factor(year), data = data_placebo) summary(did_placebo) 4.3.4 Interpretation Pre-Treatment Trends: The plot checks if readmission rates for treated and control clinics followed parallel trends before 2023, supporting the parallel trends assumption. DiD Estimate: The regression coefficient on the interaction term (\\(\\text{treated} \\cdot \\text{time}\\)) estimates the treatment effect, adjusted for patient age. The manual calculation confirms this estimate. Placebo Test: Applying DiD to pre-treatment years (2022 vs. 2023) should yield an insignificant effect, reinforcing the validity of the parallel trends assumption. In our simulation, the estimated effect is close to the true effect (-3%), indicating that the telemedicine program reduced readmissions by approximately 3 percentage points. 4.4 Limitations and Extensions Parallel Trends Violation: If pre-treatment trends diverge, DiD estimates may be biased. Techniques like synthetic controls or triple differences can address this. Time-Varying Confounders: Unobserved factors changing differentially between groups (e.g., new healthcare policies) can bias results. Including relevant covariates mitigates this. Generalizability: The ATT applies to the treated group. Generalizing to other populations requires caution. Extensions: For staggered treatment timing or multiple periods, generalized DiD models or fixed-effects regressions can be used. 4.5 Conclusion Difference-in-Differences is a powerful quasi-experimental method for causal inference, particularly in healthcare settings where randomized trials are impractical. By leveraging panel data and the parallel trends assumption, DiD isolates treatment effects with intuitive appeal. Our healthcare example demonstrated how DiD can evaluate a telemedicine program’s impact on readmissions, with R code providing a practical implementation. Diagnostics like pre-treatment trend checks and placebo tests enhance robustness. In future posts, we’ll explore advanced methods like Regression Discontinuity and Synthetic Controls to further expand the causal inference toolkit. 4.6 References Angrist, J. D., &amp; Pischke, J.-S. (2009). Mostly Harmless Econometrics. Princeton University Press. Abadie, A. (2005). Semiparametric difference-in-differences estimators. Review of Economic Studies, 72(1), 1–19. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. Wooldridge, J. M. (2010). Econometric Analysis of Cross Section and Panel Data. MIT Press. "],["causal-inference-in-practice-iv-instrumental-variables-in-healthcare.html", "Chapter 5 Causal Inference in Practice IV: Instrumental Variables in Healthcare 5.1 Introduction 5.2 Theoretical Framework 5.3 Healthcare Application: Hospital Quality and Recovery Time 5.4 Interpretation 5.5 Limitations 5.6 Conclusion 5.7 References", " Chapter 5 Causal Inference in Practice IV: Instrumental Variables in Healthcare 5.1 Introduction Establishing causal relationships in observational studies is challenging due to confounding, where unobserved factors influence both treatment assignment and outcomes, leading to biased estimates. While methods like propensity score matching or Difference-in-Differences address specific confounding scenarios, they often rely on strong assumptions, such as conditional ignorability or parallel trends, which may not hold when key confounders are unmeasured. Instrumental Variables (IV) estimation offers a robust alternative by leveraging exogenous variation to estimate causal effects, even in the presence of unobserved confounding, making it particularly valuable in settings like healthcare where randomized trials may be infeasible or unethical. This essay explores the IV method, detailing its theoretical framework, mathematical formalism, and practical application in a healthcare context—estimating the causal effect of hospital quality on patient recovery time. Using simulated data, we implement IV estimation in R, verify key assumptions, and compare results with naive approaches. We also discuss the method’s strengths, limitations, and contrasts with other causal inference techniques, providing a clear and practical guide for researchers. 5.2 Theoretical Framework 5.2.1 Motivation and Identification In observational data studies, unmeasured confounding violates the conditional ignorability assumption, i.e., $Y(1), Y(0) D X$, where $Y(1)$ and $Y(0)$ are potential outcomes under treatment ($D = 1$) and control ($D = 0$), and $X$ represents observed covariates. IV methods address this by using an instrument $Z$, a variable that induces variation in the treatment $D$ but affects the outcome $Y$ only through $D$. A valid instrument must satisfy three conditions: Relevance: The instrument must be correlated with the treatment, formally $(Z, D) $. Exclusion Restriction: The instrument affects the outcome only through the treatment, i.e., $Y = f(D, X, )$, with $Z f$. Independence: The instrument is exogenous, independent of unobserved confounders affecting the outcome, i.e., $Z X$. When these hold, IV identifies the Local Average Treatment Effect (LATE), the causal effect for compliers—individuals whose treatment status is influenced by the instrument. Unlike the Average Treatment Effect (ATE), which applies to the entire population, LATE is specific to this subpopulation, a trade-off for addressing unmeasured confounding. 5.2.2 Estimation For binary instruments and treatments, the IV estimand is given by the Wald estimator: \\[ \\widehat{\\text{LATE}} = \\frac{\\mathbb{E}[Y \\mid Z = 1] - \\mathbb{E}[Y \\mid Z = 0]}{\\mathbb{E}[D \\mid Z = 1] - \\mathbb{E}[D \\mid Z = 0]} \\] This ratio scales the reduced-form effect (instrument on outcome) by the first-stage effect (instrument on treatment). In general settings with continuous variables or covariates, two-stage least squares (2SLS) is used: First Stage: Regress the treatment on the instrument and covariates: \\[ D_i = \\pi_0 + \\pi_1 Z_i + \\pi_2^\\top X_i + \\nu_i \\] Second Stage: Regress the outcome on the predicted treatment and covariates: \\[ Y_i = \\alpha_0 + \\alpha_1 \\hat{D}_i + \\alpha_2^\\top X_i + \\varepsilon_i \\] The coefficient $_1$ estimates the LATE, consistent under valid IV assumptions, even with unmeasured confounding. 5.2.3 Comparison with Other Methods IV differs from propensity score methods, which assume conditional ignorability and estimate ATE or ATT, requiring all confounders to be observed. IV, by contrast, handles unmeasured confounding but requires a valid instrument and estimates LATE. Difference-in-Differences (DiD) relies on parallel trends, assuming untreated units represent the counterfactual trend, and is suited for time-varying treatments but cannot address confounding that varies differentially over time. IV’s strength lies in its robustness to hidden bias, though it demands careful instrument selection and limits generalizability to compliers. 5.3 Healthcare Application: Hospital Quality and Recovery Time 5.3.1 Scenario We aim to estimate the causal effect of hospital quality ($D_i = 1$ for high-quality hospitals, $D_i = 0$ for standard hospitals) on recovery time after surgery ($Y_i$, in days, lower is better). Naive regression, $Y_i = _0 + _1 D_i + _2^X_i + _i$, may be biased due to unmeasured confounders like patient health consciousness, which affects both hospital choice and recovery. We use geographic proximity to a high-quality hospital ($Z_i = 1$ if within 10 miles, $Z_i = 0$ otherwise) as an instrument, assuming patients closer to high-quality hospitals are more likely to choose them, but proximity affects recovery only through hospital choice. 5.3.2 Assumptions Relevance: Proximity influences hospital choice ($(Z_i, D_i) $), testable via the first-stage F-statistic. Exclusion Restriction: Proximity affects recovery only through hospital choice, not via other pathways like local healthcare quality. Independence: Proximity is uncorrelated with unmeasured confounders (e.g., health consciousness), plausible after controlling for observables like income or education. 5.3.3 R Implementation We simulate data for 1000 patients, with a true LATE of -5 days (high-quality hospitals reduce recovery time by 5 days for compliers). The R code below implements 2SLS, computes the Wald estimator, and compares with naive OLS. if (!requireNamespace(&quot;AER&quot;, quietly = TRUE)) install.packages(&quot;AER&quot;) if (!requireNamespace(&quot;ggplot2&quot;, quietly = TRUE)) install.packages(&quot;ggplot2&quot;) library(AER) library(ggplot2) # Set seed for reproducibility set.seed(123) # Simulate data n &lt;- 1000 # Number of patients p &lt;- 5 # Number of covariates X &lt;- matrix(rnorm(n * p), nrow = n) # Covariates (e.g., age, comorbidities) colnames(X) &lt;- paste0(&quot;X&quot;, 1:p) # Instrument: Z = 1 if within 10 miles Z &lt;- rbinom(n, 1, 0.5) # Treatment: D = 1 for high-quality hospital pi_1 &lt;- 0.8 # Strong instrument effect D &lt;- as.numeric(runif(n) &lt; plogis(0.5 + pi_1 * Z + 0.2 * rowSums(X[, 1:2]))) # Outcome: Recovery time (days) true_late &lt;- -5 Y &lt;- 20 + true_late * D + 2 * rowSums(X[, 1:3]) + rnorm(n, sd = 2) # Data frame data &lt;- data.frame(Y = Y, D = D, Z = Z, X) # First stage: Check relevance first_stage &lt;- lm(D ~ Z + ., data = data[, c(&quot;D&quot;, &quot;Z&quot;, paste0(&quot;X&quot;, 1:p))]) cat(&quot;First-stage F-statistic:&quot;, summary(first_stage)$fstatistic[1], &quot;\\n&quot;) # 2SLS estimation iv_model &lt;- ivreg(Y ~ D + . | Z + ., data = data[, c(&quot;Y&quot;, &quot;D&quot;, &quot;Z&quot;, paste0(&quot;X&quot;, 1:p))]) iv_results &lt;- summary(iv_model) cat(&quot;2SLS LATE estimate:&quot;, coef(iv_results)[&quot;D&quot;, &quot;Estimate&quot;], &quot;\\n&quot;) cat(&quot;Standard error:&quot;, coef(iv_results)[&quot;D&quot;, &quot;Std. Error&quot;], &quot;\\n&quot;) # Wald estimator y_z1 &lt;- mean(data$Y[data$Z == 1]) y_z0 &lt;- mean(data$Y[data$Z == 0]) d_z1 &lt;- mean(data$D[data$Z == 1]) d_z0 &lt;- mean(data$D[data$Z == 0]) wald_estimate &lt;- (y_z1 - y_z0) / (d_z1 - d_z0) cat(&quot;Wald estimator LATE:&quot;, wald_estimate, &quot;\\n&quot;) # Naive OLS ols_model &lt;- lm(Y ~ D + ., data = data[, c(&quot;Y&quot;, &quot;D&quot;, paste0(&quot;X&quot;, 1:p))]) ols_estimate &lt;- coef(ols_model)[&quot;D&quot;] cat(&quot;Naive OLS estimate:&quot;, ols_estimate, &quot;\\n&quot;) # Visualize results estimates &lt;- data.frame( Method = c(&quot;2SLS&quot;, &quot;Wald&quot;, &quot;OLS&quot;), Estimate = c(coef(iv_results)[&quot;D&quot;, &quot;Estimate&quot;], wald_estimate, ols_estimate), SE = c(coef(iv_results)[&quot;D&quot;, &quot;Std. Error&quot;], NA, summary(ols_model)$coefficients[&quot;D&quot;, &quot;Std. Error&quot;]), Lower = c(coef(iv_results)[&quot;D&quot;, &quot;Estimate&quot;] - 1.96 * coef(iv_results)[&quot;D&quot;, &quot;Std. Error&quot;], NA, ols_estimate - 1.96 * summary(ols_model)$coefficients[&quot;D&quot;, &quot;Std. Error&quot;]), Upper = c(coef(iv_results)[&quot;D&quot;, &quot;Estimate&quot;] + 1.96 * coef(iv_results)[&quot;D&quot;, &quot;Std. Error&quot;], NA, ols_estimate + 1.96 * summary(ols_model)$coefficients[&quot;D&quot;, &quot;Std. Error&quot;]) ) ggplot(estimates, aes(x = Method, y = Estimate, fill = Method)) + geom_bar(stat = &quot;identity&quot;, alpha = 0.6) + geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, na.rm = TRUE) + geom_hline(yintercept = true_late, linetype = &quot;dashed&quot;, color = &quot;red&quot;) + labs(title = &quot;Estimated Effect of Hospital Quality on Recovery Time&quot;, y = &quot;Effect (Days)&quot;, x = &quot;Method&quot;) + scale_fill_manual(values = c(&quot;2SLS&quot; = &quot;#1f77b4&quot;, &quot;Wald&quot; = &quot;#ff7f0e&quot;, &quot;OLS&quot; = &quot;#2ca02c&quot;)) + theme_minimal() + annotate(&quot;text&quot;, x = 3.5, y = true_late + 0.5, label = &quot;True LATE&quot;, color = &quot;red&quot;) 5.4 Interpretation The first-stage F-statistic assesses relevance; values above 10 indicate a strong instrument. In our simulation, ($_1 = 0.8$) ensures relevance. The 2SLS estimate ($_1$) should approximate the true LATE (-5 days), with confidence intervals reflecting precision. The Wald estimator, computed manually, should align closely with 2SLS but may be less precise without covariates. Naive OLS, ignoring unmeasured confounding, often yields biased estimates, typically attenuated toward zero. The plot visualizes these estimates, with 2SLS and Wald near -5 and OLS deviating, highlighting IV’s ability to correct for confounding. Exclusion and independence assumptions rely on domain knowledge. Proximity is assumed to affect recovery only through hospital choice, not via other channels like local healthcare quality. Independence holds if proximity is uncorrelated with unmeasured confounders, plausible after adjusting for observables. 5.5 Limitations IV estimation faces several challenges. Weak instruments (low first-stage F-statistic) lead to biased and imprecise estimates. Violation of the exclusion restriction, e.g., if proximity affects recovery through local resources, biases the LATE. Similarly, correlation between the instrument and unmeasured confounders violates independence. The LATE applies only to compliers, limiting generalizability to the broader population. Multiple instruments or endogenous variables require additional assumptions and tests, such as the Hansen J-test for overidentification. Heterogeneous treatment effects further complicate interpretation, as the LATE may not reflect effects for non-compliers. 5.6 Conclusion Instrumental Variables is a powerful tool for causal inference in observational studies, particularly in healthcare where unmeasured confounding is common. By leveraging an exogenous instrument like geographic proximity, IV can estimate causal effects, such as the impact of hospital quality on recovery time, even when randomized trials are impractical. The R implementation demonstrates practical application, with diagnostics ensuring assumption validity. While IV requires careful instrument selection and assumption justification, its ability to address hidden bias makes it indispensable for robust causal inference. Future research can explore extensions, such as handling heterogeneous effects or integrating IV with machine learning for improved precision. 5.7 References Angrist, J. D., &amp; Pischke, J.-S. (2009). Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press. Wooldridge, J. M. (2010). Econometric Analysis of Cross Section and Panel Data. MIT Press. Imbens, G. W., &amp; Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction. Cambridge University Press. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
