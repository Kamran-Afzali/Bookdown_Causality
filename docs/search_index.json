[["index.html", "Causal Inference in R Chapter 1 Foundations of Causal Statistical Analysis 1.1 Introduction 1.2 Summary Table: Techniques for Causal Statistical Analysis 1.3 Methodological Deep Dive with Practical Guidance 1.4 Discussion 1.5 References", " Causal Inference in R Kamran Afzali 2025-08-20 Chapter 1 Foundations of Causal Statistical Analysis 1.1 Introduction Understanding causality is one of the most enduring and fundamental challenges in science. Across disciplines—from public health and economics to education, neuroscience, and artificial intelligence—researchers are increasingly tasked not only with identifying patterns in data but with uncovering the mechanisms that generate them. While traditional statistical analysis excels at quantifying associations, scientific inquiry often aims at a deeper ambition: to infer causal relationships—to determine what would happen under specific interventions, policies, or changes to a system. The distinction between correlation and causation is more than a methodological nuance; it defines the boundary between description and explanation, and between prediction and control. This essay serves as the first in a multi-part series on the foundations of causal statistical analysis. It provides a panoramic overview of the most widely used techniques for estimating causal effects, each grounded in distinct theoretical frameworks and operational assumptions. These methods span randomized controlled trials (RCTs), which serve as the epistemic gold standard, to a wide range of quasi-experimental and model-based approaches developed to address the limitations of real-world data. In practice, researchers must often navigate data landscapes in which randomization is infeasible, treatment selection is endogenous, and temporal or structural confounding is ubiquitous. This is where modern causal inference techniques offer essential tools—not only for estimating effects, but for interrogating the validity of those estimates. At the heart of this endeavor lies a tension between identifiability and assumptions. Every causal method rests on a set of assumptions—about how the data were generated, how variables relate, and what sources of bias are controlled or ignored. While some methods emphasize robustness through design (e.g., difference-in-differences, regression discontinuity, or instrumental variables), others attempt to model the data-generating process explicitly, drawing from structural modeling, counterfactual reasoning, or machine learning. Each method is powerful under the right conditions and misleading when applied uncritically. This underscores a central theme of the series: there is no universally “best” method for causal inference. Rather, the suitability of each technique depends on the scientific question, data structure, and the plausibility of underlying assumptions. To guide practitioners in this complex terrain, we begin with a comparative summary table outlining the assumptions, strengths, limitations, and implementation tools for each technique. This table is not merely a catalog—it is a scaffold for deeper engagement. Subsequent posts in the series will explore each method in detail, presenting both theoretical foundations and practical workflows using open-source statistical packages in R and Python. These installments will include visualizations, diagnostics, sensitivity analyses, and real-world case studies drawn from public health, education, and policy evaluation. Causal analysis is both an art and a science: it demands careful reasoning, domain knowledge, and transparent methodology. As the demand for evidence-based decision-making grows—particularly in the age of big data and algorithmic governance—causal inference provides a principled framework for moving from data to action. This series is designed to empower readers to approach causal questions rigorously, critically, and creatively. 1.2 Summary Table: Techniques for Causal Statistical Analysis Technique Key Assumptions Use Cases Strengths Limitations Tools/Packages Randomized Controlled Trials (RCTs) Random assignment ensures exchangeability Clinical trials, A/B testing Eliminates confounding Often infeasible or unethical randomizr (R), DoWhy (Py) Regression Adjustment No unmeasured confounders, correct model Policy, health outcomes Simple, widely used Sensitive to omitted variables, model misspecification lm(), glm() (R), statsmodels, sklearn (Py) Propensity Score Matching (PSM) Conditional independence given observed covariates Observational studies Balances covariates, intuitive Sensitive to unmeasured confounding, poor overlap MatchIt, twang (R), DoWhy, causalml (Py) Inverse Probability Weighting (IPW) Correct treatment model, positivity Longitudinal data Handles time-varying confounding Can produce unstable weights ipw, survey (R), zEpid (Py) Difference-in-Differences (DiD) Parallel trends Policy reforms, natural experiments Controls for unobserved time-invariant confounders Vulnerable if trends diverge fixest, did (R), linearmodels (Py) Instrumental Variables (IV) Relevance, exclusion restriction Endogeneity correction Addresses unmeasured confounding Finding valid instruments is hard ivreg, AER (R), linearmodels.iv (Py) Regression Discontinuity (RDD) Sharp cutoff, local randomization Education, policy thresholds Transparent identification Limited to local effect near cutoff rdrobust, rddtools (R), rdd, statsmodels (Py) Causal Forests Unconfoundedness, heterogeneity Precision medicine, targeting Captures treatment heterogeneity Requires large data, unmeasured confounding risk grf, causalTree (R), econml, causalml (Py) Bayesian Structural Time Series (BSTS) No unmeasured confounders post-intervention Time series interventions Handles complex time trends Sensitive to model/priors CausalImpact, bsts (R), tfcausalimpact (Py) Targeted Maximum Likelihood Estimation (TMLE) Double robustness Epidemiology, observational data Robust, ML integration Computationally intensive tmle, ltmle (R), zepid (Py) G-Computation No unmeasured confounding, correct model Mediation, marginal effects Flexible, counterfactuals Model dependence gfoRmula, ltmle (R), zepid (Py) Structural Equation Modeling (SEM) Correct structure, no unmeasured confounding Latent variables, mediation Models complex relationships Requires strong assumptions lava RESOLVED: lavaan (R), semopy, pysem (Py) Directed Acyclic Graphs (DAGs) Causal sufficiency, accurate knowledge Study design, confounder control Clarifies assumptions Not an estimation method dagitty, ggdag (R), causalgraphicalmodels (Py) Double Machine Learning (DML) Frameworks Conditional ignorability, consistent nuisance estimation High-dimensional observational studies Robust to model misspecification, handles high-dimensional confounders Requires large data, assumes no unmeasured confounding DoubleML (R), econml, causalml (Py) 1.3 Methodological Deep Dive with Practical Guidance Randomized Controlled Trials (RCTs) RCTs are the gold standard for causal inference. Random assignment neutralizes confounding, ensuring internal validity. However, practical, ethical, or financial constraints often limit their feasibility. When viable, they deliver the most credible causal estimates. Regression Adjustment This method models the outcome as a function of treatment and covariates. While easy to implement, it assumes no unmeasured confounding and correct model specification. It’s essential to examine covariate balance and conduct robustness checks. Propensity Score Matching (PSM) PSM aims to mimic randomization by matching units with similar probabilities of treatment. It balances covariates well but fails under unmeasured confounding. Diagnostic tools like balance plots are crucial. Inverse Probability Weighting (IPW) IPW reweights samples to simulate random assignment. It handles time-varying confounding but can produce unstable weights, requiring trimming or stabilization. It’s powerful for longitudinal and panel data. Difference-in-Differences (DiD) DiD compares treated and control units over time, assuming parallel trends. It is popular for evaluating policy interventions but sensitive to trend violations. Visualizing pre-treatment trends and using placebo tests enhance credibility. Instrumental Variables (IV) IV methods handle endogeneity by using external variables that affect treatment but not the outcome directly. The approach hinges on the strength and validity of instruments—criteria that are difficult to verify. Regression Discontinuity Design (RDD) RDD exploits sharp cutoffs for treatment assignment. It provides quasi-experimental validity but estimates only local effects near the threshold. Validity depends on smoothness and non-manipulation at the cutoff. Causal Forests Causal forests extend random forests to estimate heterogeneous treatment effects. They are ideal for personalized interventions but require large datasets and are vulnerable to omitted confounding. Bayesian Structural Time Series (BSTS) BSTS combines state-space models with Bayesian inference to estimate intervention effects in time series. It accommodates trend and seasonality but is sensitive to model misspecification and prior choices. Targeted Maximum Likelihood Estimation (TMLE) TMLE integrates machine learning into causal effect estimation. It provides double robustness and efficient inference under complex data settings but can be computationally demanding. G-Computation G-computation models potential outcomes under each treatment. It is flexible and counterfactual-based but requires accurate modeling and complete covariate adjustment. Structural Equation Modeling (SEM) SEM enables the modeling of complex causal structures, including latent constructs and mediation. Its interpretability is appealing but hinges on correct model specification and the absence of unmeasured confounding. Directed Acyclic Graphs (DAGs) DAGs are essential for clarifying causal assumptions. While not an estimation method, they guide design and analysis by identifying confounders, mediators, and colliders. 1.4 Discussion The comparative framework presented in this foundational overview highlights both the diversity and the interdependence of causal inference techniques. A central takeaway is that no single method guarantees valid causal inference in all contexts. Rather, the validity of any technique depends critically on whether its assumptions align with the structure of the data and the theoretical understanding of the system under study. This observation has two key implications for applied researchers. First, triangulation—the use of multiple methods to approach the same causal question—is not only desirable but often necessary. For instance, one might use propensity score matching to achieve covariate balance, regression adjustment to model outcome differences, and then compare results with those from a targeted maximum likelihood estimation (TMLE) approach. If conclusions converge, confidence in causal interpretation increases. If not, divergences can reveal sensitivity to assumptions such as model specification or unmeasured confounding. Thus, causal inference is inherently iterative, requiring both methodological flexibility and diagnostic rigor. Second, methodological literacy is not enough; researchers must also cultivate causal reasoning. Directed Acyclic Graphs (DAGs), while not themselves estimators, play a vital role in clarifying which variables to control for and which paths to block or preserve. DAG-based thinking helps researchers navigate common pitfalls such as controlling for colliders or mediators, both of which can induce bias. The thoughtful use of DAGs, therefore, bridges qualitative theoretical insight with quantitative estimation. Another tension arises between interpretability and complexity. Classical techniques like regression or instrumental variables are often preferred for their clarity and theoretical grounding, while modern approaches such as causal forests and TMLE offer increased flexibility and robustness in high-dimensional or non-linear settings. However, these gains often come at the cost of interpretability, especially for stakeholders or policy-makers who require transparent causal narratives. This raises an important trade-off: when should we prioritize explainability over precision, and how do we communicate these decisions to interdisciplinary audiences? In addition, the growing use of machine learning in causal inference—exemplified by methods like causal forests and TMLE—requires new standards for validation and transparency. Unlike predictive modeling, causal questions are inherently counterfactual and cannot be validated through conventional cross-validation. Techniques such as falsification tests, placebo analyses, and sensitivity analyses become indispensable, particularly when machine learning models are involved. Finally, equity and ethics must be central to causal analysis, especially in domains like public health, criminal justice, and education. Methods that adjust for observed variables can inadvertently perpetuate structural inequalities if those variables are themselves proxies for systemic bias. Researchers must therefore engage critically with both the data and the social contexts from which they arise, treating causal models not just as statistical tools but as ethical instruments. The subsequent posts in this series will explore each technique in depth, including code implementation, diagnostic strategies, and real-world case studies. By weaving together statistical rigor, domain expertise, and ethical reflexivity, we aim to equip researchers with a robust and responsible causal toolkit. 1.5 References Hernán &amp; Robins (2020). Causal Inference: What If. Pearl, Glymour, &amp; Jewell (2016). Causal Inference in Statistics: A Primer. VanderWeele (2015). Explanation in Causal Inference. Causal AI Blog by Judea Pearl: https://causality.cs.ucla.edu/blog/ Netflix Tech Blog on Causal Inference: https://netflixtechblog.com/computational-causal-inference-at-netflix-293591691c62 Number Analytics Education Series: https://www.numberanalytics.com/blog/ "],["causal-inference-in-practice-i-randomized-controlled-trials-and-regression-adjustment.html", "Chapter 2 Causal Inference in Practice I: Randomized Controlled Trials and Regression Adjustment 2.1 Introduction 2.2 1. Randomized Controlled Trials: Design and Analysis 2.3 2. Regression Adjustment: A Model-Based Approach to Causal Inference 2.4 Toward Integrated Reasoning 2.5 Conclusion", " Chapter 2 Causal Inference in Practice I: Randomized Controlled Trials and Regression Adjustment 2.1 Introduction In the first post of this series, we presented a comprehensive overview of key causal inference methods, highlighting the assumptions, strengths, and limitations that distinguish each technique. In this follow-up post, we delve into the two most foundational approaches: Randomized Controlled Trials (RCTs) and Regression Adjustment. Although these methods differ in their reliance on data-generating processes and assumptions, both provide crucial entry points into the logic of causal reasoning. This essay offers a theoretically grounded and practically oriented treatment of each method, including code implementation in R, diagnostics, and interpretive guidance. RCTs represent the epistemic benchmark for causal inference, often described as the “gold standard” due to their unique ability to eliminate confounding through randomization. Regression Adjustment, by contrast, models the outcome conditional on treatment and covariates, requiring more assumptions but offering wide applicability in observational settings. Despite their differences, both approaches are underpinned by counterfactual reasoning—the idea that causal effects reflect the difference between what actually happened and what would have happened under a different treatment assignment. Understanding the logic and implementation of these two methods is essential not only for their direct use but also because they serve as the conceptual and statistical scaffolding for more complex techniques such as matching, weighting, and doubly robust estimators. 2.2 1. Randomized Controlled Trials: Design and Analysis 2.2.1 Theoretical Foundations In an RCT, participants are randomly assigned to treatment or control groups. This process ensures that, on average, both groups are statistically equivalent on all covariates, observed and unobserved. The core assumption is exchangeability—that the potential outcomes are independent of treatment assignment conditional on randomization. This enables simple comparisons of mean outcomes across groups to yield unbiased estimates of causal effects. Formally, let \\(Y(1)\\) and \\(Y(0)\\) denote the potential outcomes under treatment and control, respectively. The average treatment effect (ATE) is defined as: \\[ \\text{ATE} = \\mathbb{E}[Y(1) - Y(0)] \\] In a perfectly randomized trial, we estimate the ATE by comparing the sample means: \\[ \\widehat{\\text{ATE}} = \\bar{Y}_1 - \\bar{Y}_0 \\] This estimator is unbiased and consistent, provided randomization is successfully implemented and compliance is perfect. 2.2.2 R Implementation Let’s simulate a simple RCT to estimate the effect of a binary treatment on an outcome. # Load necessary libraries library(tidyverse) # Set seed for reproducibility set.seed(123) # Simulate data n &lt;- 1000 data_rct &lt;- tibble( treatment = rbinom(n, 1, 0.5), outcome = 5 + 2 * treatment + rnorm(n) ) # Estimate ATE using difference in means ate_estimate &lt;- data_rct %&gt;% group_by(treatment) %&gt;% summarise(mean_outcome = mean(outcome)) %&gt;% summarise(ATE = diff(mean_outcome)) print(ate_estimate) 2.2.3 Model-Based Inference While RCTs do not require model-based adjustments, regression models are often used to improve precision or adjust for residual imbalances. In the RCT context, such models are descriptive rather than corrective. # Linear regression with treatment as predictor lm_rct &lt;- lm(outcome ~ treatment, data = data_rct) summary(lm_rct) The coefficient on the treatment variable in this model provides an estimate of the ATE. Importantly, in randomized designs, the inclusion of additional covariates should not substantially alter the point estimate, though it may reduce variance. 2.2.4 Diagnostics and Integrity Although randomization ensures internal validity, its practical implementation must be verified. Balance diagnostics, such as standardized mean differences or visualizations of covariate distributions by treatment group, help ensure that the groups are equivalent at baseline. If substantial imbalances exist, especially in small samples, model-based covariate adjustment can improve efficiency but not eliminate bias due to poor randomization. 2.3 2. Regression Adjustment: A Model-Based Approach to Causal Inference 2.3.1 Conceptual Overview Regression Adjustment, sometimes called covariate adjustment, is one of the most widely used methods for causal estimation in observational studies. Unlike RCTs, this approach requires the assumption of no unmeasured confounding, often called conditional ignorability: \\[ Y(1), Y(0) \\perp D \\mid X \\] Here, \\(D\\) is the binary treatment variable and \\(X\\) is a vector of observed covariates. The central idea is to control for confounders \\(X\\) that affect both treatment assignment and potential outcomes. The linear model typically takes the form: \\[ Y = \\beta_0 + \\beta_1 D + \\beta_2 X + \\varepsilon \\] The coefficient \\(\\beta_1\\) is interpreted as the average treatment effect, assuming the model is correctly specified and all relevant confounders are included. 2.3.2 R Implementation We now simulate observational data with a confounder to demonstrate regression adjustment. # Simulate observational data set.seed(123) n &lt;- 1000 x &lt;- rnorm(n) d &lt;- rbinom(n, 1, plogis(0.5 * x)) y &lt;- 5 + 2 * d + 1.5 * x + rnorm(n) data_obs &lt;- tibble( treatment = d, covariate = x, outcome = y ) # Naive model (without adjustment) lm_naive &lt;- lm(outcome ~ treatment, data = data_obs) summary(lm_naive) # Adjusted model lm_adjusted &lt;- lm(outcome ~ treatment + covariate, data = data_obs) summary(lm_adjusted) The naive model, which omits the confounder, yields a biased estimate of the treatment effect. By contrast, the adjusted model corrects this bias, provided all relevant confounders are included and the functional form is correct. 2.3.3 Limitations and Diagnostics Regression Adjustment hinges on correct model specification and the inclusion of all relevant confounders. Omitted variable bias remains a major threat, and multicollinearity or misspecified functional forms can distort estimates. Residual plots, variance inflation factors, and specification tests are essential for model diagnostics. Moreover, regression does not address overlap—the requirement that all units have a non-zero probability of receiving each treatment conditional on covariates. Violations of this assumption can lead to extrapolation and poor generalizability. One strategy to assess covariate overlap is to model the propensity score and visualize its distribution across treatment groups. # Estimate propensity scores ps_model &lt;- glm(treatment ~ covariate, data = data_obs, family = binomial()) data_obs &lt;- data_obs %&gt;% mutate(pscore = predict(ps_model, type = &quot;response&quot;)) # Plot propensity scores ggplot(data_obs, aes(x = pscore, fill = factor(treatment))) + geom_density(alpha = 0.5) + labs(fill = &quot;Treatment Group&quot;, title = &quot;Propensity Score Overlap&quot;) If there is poor overlap between groups, regression adjustment may yield estimates with high variance and questionable validity. 2.3.4 Causal Interpretation While regression models provide estimates of conditional treatment effects, care must be taken in interpreting these coefficients causally. The treatment effect estimated by regression adjustment is unbiased only under strong assumptions: no unmeasured confounding, correct model specification, and sufficient overlap. This makes regression adjustment a double-edged sword. Its ease of use and interpretability make it appealing, but its susceptibility to hidden bias requires rigorous scrutiny. 2.4 Toward Integrated Reasoning The juxtaposition of RCTs and regression adjustment highlights the contrast between design-based and model-based inference. RCTs achieve causal identification through the randomization mechanism itself, rendering statistical adjustment unnecessary (but sometimes helpful for precision). Regression adjustment, on the other hand, relies entirely on the plausibility of its assumptions, making it vulnerable to hidden confounding and specification errors. Importantly, these methods should not be viewed in isolation. Hybrid designs and analytic strategies—such as regression adjustment in RCTs or design-based diagnostics in observational studies—blur the boundaries and point toward more integrated approaches to causal inference. Furthermore, emerging methods such as doubly robust estimation, propensity score weighting, and machine learning–based causal estimators build upon the foundations established by these two methods. Understanding the mechanics and logic of RCTs and regression adjustment is thus a prerequisite for mastering more advanced techniques. 2.5 Conclusion In this installment, we explored the theoretical rationale, implementation, and practical considerations of two cornerstone methods in causal inference: Randomized Controlled Trials and Regression Adjustment. RCTs provide unmatched causal credibility when feasible, while regression models offer flexible tools for analyzing observational data under strong assumptions. Their complementary roles in the causal inference toolkit make them indispensable for any applied researcher. The next entry in this series will turn to Propensity Score Methods, where we will examine how matching and weighting strategies seek to approximate randomized experiments using observational data. As with all causal methods, the key lies not just in computation, but in the clarity of assumptions and the integrity of reasoning. By combining design principles, diagnostic rigor, and ethical sensitivity, causal inference offers a powerful framework for navigating the complexity of real-world data. "],["causal-inference-in-practice-ii-propensity-scores-doubly-robust-estimators-and-inverse-probability-weighting.html", "Chapter 3 Causal Inference in Practice II: Propensity Scores, Doubly Robust Estimators, and Inverse Probability Weighting 3.1 Propensity Score Methods 3.2 Inverse Probability Weighting (IPW) 3.3 Doubly Robust Estimators 3.4 Integrative Interpretation 3.5 Summary Table 3.6 Conclusion 3.7 References", " Chapter 3 Causal Inference in Practice II: Propensity Scores, Doubly Robust Estimators, and Inverse Probability Weighting The previous post investigated the foundations of Randomized Controlled Trials and Regression Adjustment. In real-world observational data, achieving balance on covariates is challenging, and simple regression models rely heavily on conditional independence and correct model specification. Propensity score–based methods, including matching, Inverse Probability Weighting (IPW), and doubly robust estimation, offer suitable alternatives. These methods alleviate some assumptions but introduce others such as positivity and model correctness. In this essay, we articulate their theoretical motivations, derive formal estimators, and demonstrate implementation in R. 3.1 Propensity Score Methods Propensity score methods serve to emulate a randomized trial by balancing observed confounders across treatment groups. The propensity score \\(e(x) = P(D=1 \\mid X=x)\\) compresses multivariate covariate information into a single scalar. Under the assumption of conditional ignorability (\\(Y(1),Y(0) \\perp D \\mid X\\)) and overlap (\\(0 &lt; e(x) &lt; 1\\)), adjusting for \\(e(x)\\) suffices to remove bias due to observed covariates. Formally, denote the propensity score–adjusted estimator: \\[ \\widehat{\\text{ATE}} = \\frac{1}{n} \\sum_{i=1}^n \\left( \\frac{D_i Y_i}{\\hat e(X_i)} - \\frac{(1-D_i)Y_i}{1 - \\hat e(X_i)} \\right). \\] In practice, one normally models \\(e(x)\\) with logistic regression: library(tidyverse) set.seed(42) n &lt;- 2000 x1 &lt;- rnorm(n) x2 &lt;- rbinom(n,1,0.3) e &lt;- plogis(-0.5 + 0.8 * x1 - 0.4 * x2) d &lt;- rbinom(n,1,e) y &lt;- 3 + 2 * d + 1.2 * x1 - 0.5 * x2 + rnorm(n) data &lt;- tibble(x1, x2, treatment = d, outcome = y) ps_model &lt;- glm(treatment ~ x1 + x2, data = data, family = binomial) data &lt;- data %&gt;% mutate(pscore = predict(ps_model, type = &quot;response&quot;)) ggplot(data, aes(x = pscore, color = factor(treatment))) + geom_density() + labs(title = &quot;Propensity Score by Treatment Group&quot;) To estimate ATE by matching: library(MatchIt) match_out &lt;- matchit(treatment ~ x1 + x2, data = data, method = &quot;nearest&quot;, ratio = 1) matched &lt;- match.data(match_out) lm_matched &lt;- lm(outcome ~ treatment, data = matched) summary(lm_matched) lm_non_matched &lt;- lm(outcome ~ treatment, data = data) summary(lm_non_matched) plot(match_out, type = &quot;qq&quot;, interactive = FALSE) Here, coefficients() for treatment gives the ATE among matched units, interpretable under the assumption of balance on \\(X\\). Diagnostics should include covariate balance checks after matching (e.g., plot(match_out, type=\"jitter\")). 3.2 Inverse Probability Weighting (IPW) IPW uses propensity score–based weighting to reweight the sample, such that the weighted treated and control groups become exchangeable. Each subject is weighted as: \\[ w_i = \\frac{D_i}{\\hat e(X_i)} + \\frac{1-D_i}{1-\\hat e(X_i)}. \\] Then, \\[ \\widehat{\\text{ATE}}_{\\text{IPW}} = \\frac{\\sum_i w_i Y_i}{\\sum_i w_i}. \\] IPW estimates the ATE without explicit modeling of \\(E[Y \\mid D, X]\\), but hinge critically on correctly specified propensity scores and stable overlap. library(survey) data$wt &lt;- with(data, ifelse(treatment == 1, 1/pscore, 1/(1-pscore))) design &lt;- svydesign(ids = ~1, weights = ~wt, data = data) ipw_mod &lt;- svyglm(outcome ~ treatment, design = design) summary(ipw_mod) The coefficient on treatment gives the IPW-estimated ATE. One must check for extreme weights using summaries (summary(data_obs$wt)) and consider trimming. 3.3 Doubly Robust Estimators Doubly robust estimators combine outcome modeling and propensity weighting so that estimation remains consistent if either model is correctly specified. The canonical form is: \\[ \\widehat{\\text{ATE}}_{\\text{DR}} = \\frac{1}{n} \\sum_{i=1}^{n} \\left[ m_1(X_i) - m_0(X_i) + \\frac{D_i(Y_i - m_1(X_i))}{\\hat{e}(X_i)} - \\frac{(1 - D_i)(Y_i - m_0(X_i))}{1 - \\hat{e}(X_i)} \\right] \\] where \\(\\hat m(D, X)\\) is an estimated regression of outcome on treatment and covariates. om_mod &lt;- lm(outcome ~ treatment + x1 + x2, data = data) data$mu1_hat &lt;- predict(om_mod, newdata = transform(data, treatment = 1)) data$mu0_hat &lt;- predict(om_mod, newdata = transform(data, treatment = 0)) # Doubly robust ATE dr_ate &lt;- with(data, mean((treatment/pscore - (1-treatment)/(1-pscore))*(outcome - (treatment*mu1_hat + (1-treatment)*mu0_hat)) + mu1_hat - mu0_hat)) dr_ate This dr_ate estimate is doubly robust: consistent if either propensity or outcome model is correct. Practical use involves bootstrapping for variance. 3.4 Integrative Interpretation Propensity scores adjust for observed confounders in a manner motivated by design, yielding a pseudo-randomized experiment. IPW pushes this further by weighting, creating a synthetic population. Doubly robust methods guard against misspecification of either the weighting model or the outcome model—ensuring valid ATE estimation under broader conditions. However, each method remains anchored in core assumptions: ignorability, overlap, and model correctness. Diagnostics—such as balance checks after matching/IPW, weight summaries, and residual/outcome-model validation—are essential before causal claims are made. 3.5 Summary Table Method Model Requirement Consistency If Estimator Formula Primary Strength Propensity Score Matching Logistic for \\(e(x)\\) Propensity correctly estimated Difference in means after matching Balances covariates; design mimicry Inverse Probability Weighting (IPW) Logistic for \\(e(x)\\) Propensity correctly estimated Weighted regression or weighted mean difference Creates reweighted, exchangeable sample Doubly Robust Estimator Logistic for \\(e(x)\\) or outcome \\(m(D,X)\\) Either model correctly specified ATE combining weighted residuals and conditional means Robust to misspecification, efficient 3.6 Conclusion This post has advanced our series by exploring methods that bridge the gap between randomization and modeling. Propensity scores, IPW, and doubly robust estimators offer complementary strategies for tackling confounding, each accompanied by unique trade‑offs in terms of assumptions, stability, and interpretability. The next installment will explore Matching, Difference-in-Differences, and Instrumental Variables, offering further depth and methods for complex real-world data. 3.7 References Rosenbaum, P. R., &amp; Rubin, D. B. (1983). The central role of the propensity score in observational studies for causal effects. Biometrika, 70(1), 41–55. Robins, J. M., &amp; Rotnitzky, A. (1995). Semiparametric efficiency in multivariate regression models with missing data. Journal of the American Statistical Association, 90(429), 122–129. Bang, H., &amp; Robins, J. M. (2005). Doubly robust estimation in missing data and causal inference models. Biometrics, 61(4), 962–973. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. "],["causal-inference-in-practice-iii-difference-in-differences-with-a-healthcare-application.html", "Chapter 4 Causal Inference in Practice III: Difference-in-Differences with a Healthcare Application 4.1 Introduction 4.2 Difference-in-Differences: Theoretical Framework 4.3 Application: Evaluating a Telemedicine Program in Healthcare 4.4 Limitations and Extensions 4.5 Conclusion 4.6 References", " Chapter 4 Causal Inference in Practice III: Difference-in-Differences with a Healthcare Application 4.1 Introduction In observational studies, where randomized controlled trials are infeasible, causal inference methods like Difference-in-Differences (DiD) provide a robust framework for estimating treatment effects under specific assumptions. DiD is particularly valuable in settings with panel data, where units are observed over time, and some receive a treatment while others do not. By leveraging the temporal structure of data, DiD isolates the causal effect of a treatment by comparing changes in outcomes between treated and control groups over time. This approach is widely used in fields such as economics, public policy, and healthcare to evaluate interventions like policy changes or medical programs. In this post, we focus on DiD, exploring its theoretical foundations, mathematical formalism, and practical implementation. We apply DiD to a realistic healthcare example—evaluating the impact of a telemedicine program on patient outcomes—using R code to demonstrate the methodology. We also discuss diagnostics, limitations, and extensions to ensure robust causal inference. 4.2 Difference-in-Differences: Theoretical Framework 4.2.1 Core Concept DiD estimates the causal effect of a treatment by comparing the change in outcomes over time between a treated group and a control group. The method assumes that, in the absence of treatment, the treated and control groups would follow parallel trends in their outcomes. This assumption allows DiD to account for time-invariant differences between groups and common time trends affecting both groups. 4.2.2 Mathematical Formalism Let’s formalize the DiD framework. For unit \\(i\\) at time \\(t \\in \\{0, 1\\}\\) (pre- and post-treatment), define: \\(Y_{it}\\): Observed outcome for unit \\(i\\) at time \\(t\\). \\(D_i \\in \\{0, 1\\}\\): Treatment indicator (\\(D_i = 1\\) for treated units, \\(D_i = 0\\) for control units). \\(T_t \\in \\{0, 1\\}\\): Time indicator (\\(T_t = 0\\) for pre-treatment, \\(T_t = 1\\) for post-treatment). \\(Y_{it}(1), Y_{it}(0)\\): Potential outcomes under treatment and control, respectively. The causal effect of interest is the average treatment effect on the treated (ATT): \\[ \\text{ATT} = \\mathbb{E}[Y_{i1}(1) - Y_{i1}(0) \\mid D_i = 1] \\] The DiD estimator assumes that the observed outcome can be modeled as: \\[ Y_{it} = \\beta_0 + \\beta_1 D_i + \\beta_2 T_t + \\delta (D_i \\cdot T_t) + \\epsilon_{it} \\] Where: - \\(\\beta_0\\): Baseline outcome for the control group at \\(t = 0\\). - \\(\\beta_1\\): Time-invariant difference between treated and control groups. - \\(\\beta_2\\): Common time trend affecting both groups. - \\(\\delta\\): The DiD estimator, representing the ATT. - \\(\\epsilon_{it}\\): Error term, assumed to have mean zero. The DiD estimator is computed as: \\[ \\widehat{\\text{DiD}} = \\left( \\bar{Y}_{1, \\text{treated}} - \\bar{Y}_{0, \\text{treated}} \\right) - \\left( \\bar{Y}_{1, \\text{control}} - \\bar{Y}_{0, \\text{control}} \\right) \\] Where \\(\\bar{Y}_{t, g}\\) is the mean outcome for group \\(g\\) (treated or control) at time \\(t\\). 4.2.3 Key Assumption: Parallel Trends The validity of DiD hinges on the parallel trends assumption: \\[ \\mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \\mid D_i = 1] = \\mathbb{E}[Y_{i1}(0) - Y_{i0}(0) \\mid D_i = 0] \\] This assumes that, absent treatment, the average change in outcomes for the treated group would equal that of the control group. While this assumption is untestable directly (since \\(Y_{i1}(0)\\) is unobserved for the treated group post-treatment), we can assess its plausibility by examining pre-treatment trends or including covariates to adjust for potential confounders. 4.2.4 Practical Considerations Data Requirements: DiD requires panel data (same units observed over time) or repeated cross-sectional data with clear treatment and control groups. Covariates: Including control variables unaffected by the treatment can improve precision and adjust for time-varying confounders. Diagnostics: Pre-treatment trends should be visualized to assess the parallel trends assumption. Robustness checks, such as placebo tests, can further validate the model. Extensions: DiD can be extended to multiple time periods, staggered treatment adoption, or heterogeneous effects using advanced methods like generalized DiD. 4.3 Application: Evaluating a Telemedicine Program in Healthcare 4.3.1 Scenario Consider a hospital system implementing a telemedicine program in 2024 to improve patient outcomes, such as reducing hospital readmissions for chronic disease patients. The program is rolled out in select clinics (treated group), while others continue standard in-person care (control group). We observe patient outcomes (e.g., 30-day readmission rates) in 2023 (pre-treatment) and 2025 (post-treatment). Using DiD, we estimate the program’s causal effect on readmissions. 4.3.2 Simulated Data We simulate data for 200 clinics (100 treated, 100 control) with readmission rates over two years. The true treatment effect is a 3% reduction in readmissions. We include a covariate (average patient age) to account for potential confounding. 4.3.3 R Implementation Below is the R code to simulate the data, estimate the DiD effect, and perform diagnostics. # Load required packages library(ggplot2) library(dplyr) # Set seed for reproducibility set.seed(123) # Parameters n_clinics &lt;- 200 # 100 treated, 100 control time_periods &lt;- 2 # 2023 (pre), 2025 (post) true_effect &lt;- -5 # Increased effect size to -5% for stronger impact noise_sd &lt;- 0.5 # Reduced noise to make effect more detectable # Create data data &lt;- data.frame( clinic = rep(1:n_clinics, each = time_periods), time = rep(c(0, 1), times = n_clinics), # 0 = 2023, 1 = 2025 year = rep(c(2023, 2025), times = n_clinics), treated = rep(rep(c(0, 1), each = time_periods), times = n_clinics/2), age = rep(rnorm(n_clinics, mean = 65, sd = 5), each = time_periods) ) # Generate readmission rates (%) data$readmission &lt;- 20 + # Baseline readmission rate 1 * data$treated + # Treated clinics have higher baseline 2 * data$time + # Secular trend true_effect * data$treated * data$time + # Stronger treatment effect 0.1 * data$age + # Age effect rnorm(nrow(data), mean = 0, sd = noise_sd) # Reduced noise # Preview data head(data) # Check parallel trends: Pre-treatment data (2021-2023) data_pre &lt;- data.frame( clinic = rep(1:n_clinics, each = 3), year = rep(c(2021, 2022, 2023), times = n_clinics), treated = rep(rep(c(0, 1), each = 3), times = n_clinics/2), readmission = 20 + 1 * rep(rep(c(0, 1), each = 3), times = n_clinics/2) + # Group effect 2 * rep(0:2, times = n_clinics) + # Linear trend rnorm(3 * n_clinics, 0, noise_sd) # Reduced noise ) # Aggregate means for pre-treatment plot means_pre &lt;- data_pre %&gt;% group_by(year, treated) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) # Plot pre-treatment trends ggplot(means_pre, aes(x = year, y = readmission, color = factor(treated), group = treated)) + geom_line(size = 1) + geom_point(size = 2) + labs(title = &quot;Pre-Treatment Trends in Readmission Rates&quot;, x = &quot;Year&quot;, y = &quot;Readmission Rate (%)&quot;, color = &quot;Group&quot;) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;)) + theme_minimal() # Post-treatment trends for visualization means_post &lt;- data %&gt;% group_by(year, treated) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) # Plot post-treatment trends to show diverging slopes ggplot(means_post, aes(x = year, y = readmission, color = factor(treated), group = treated)) + geom_line(size = 1) + geom_point(size = 2) + labs(title = &quot;Post-Treatment Trends in Readmission Rates&quot;, x = &quot;Year&quot;, y = &quot;Readmission Rate (%)&quot;, color = &quot;Group&quot;) + scale_color_manual(values = c(&quot;blue&quot;, &quot;red&quot;), labels = c(&quot;Control&quot;, &quot;Treated&quot;)) + theme_minimal() # DiD regression with covariate did_model &lt;- lm(readmission ~ treated + time + treated:time + age, data = data) # Summary of results summary(did_model) # Manual DiD calculation means &lt;- data %&gt;% group_by(treated, time) %&gt;% summarise(readmission = mean(readmission), .groups = &quot;drop&quot;) y0_control &lt;- means$readmission[means$treated == 0 &amp; means$time == 0] y1_control &lt;- means$readmission[means$treated == 0 &amp; means$time == 1] y0_treated &lt;- means$readmission[means$treated == 1 &amp; means$time == 0] y1_treated &lt;- means$readmission[means$treated == 1 &amp; means$time == 1] did_estimate &lt;- (y1_treated - y0_treated) - (y1_control - y0_control) cat(&quot;DiD Estimate:&quot;, did_estimate, &quot;%\\n&quot;) # Placebo test: Pre-treatment periods (2022 vs. 2023) data_placebo &lt;- data_pre[data_pre$year %in% c(2022, 2023), ] did_placebo &lt;- lm(readmission ~ treated * factor(year), data = data_placebo) summary(did_placebo) 4.3.4 Interpretation Pre-Treatment Trends: The plot checks if readmission rates for treated and control clinics followed parallel trends before 2023, supporting the parallel trends assumption. DiD Estimate: The regression coefficient on the interaction term (\\(\\text{treated} \\cdot \\text{time}\\)) estimates the treatment effect, adjusted for patient age. The manual calculation confirms this estimate. Placebo Test: Applying DiD to pre-treatment years (2022 vs. 2023) should yield an insignificant effect, reinforcing the validity of the parallel trends assumption. In our simulation, the estimated effect is close to the true effect (-3%), indicating that the telemedicine program reduced readmissions by approximately 3 percentage points. 4.4 Limitations and Extensions Parallel Trends Violation: If pre-treatment trends diverge, DiD estimates may be biased. Techniques like synthetic controls or triple differences can address this. Time-Varying Confounders: Unobserved factors changing differentially between groups (e.g., new healthcare policies) can bias results. Including relevant covariates mitigates this. Generalizability: The ATT applies to the treated group. Generalizing to other populations requires caution. Extensions: For staggered treatment timing or multiple periods, generalized DiD models or fixed-effects regressions can be used. 4.5 Conclusion Difference-in-Differences is a powerful quasi-experimental method for causal inference, particularly in healthcare settings where randomized trials are impractical. By leveraging panel data and the parallel trends assumption, DiD isolates treatment effects with intuitive appeal. Our healthcare example demonstrated how DiD can evaluate a telemedicine program’s impact on readmissions, with R code providing a practical implementation. Diagnostics like pre-treatment trend checks and placebo tests enhance robustness. In future posts, we’ll explore advanced methods like Regression Discontinuity and Synthetic Controls to further expand the causal inference toolkit. 4.6 References Angrist, J. D., &amp; Pischke, J.-S. (2009). Mostly Harmless Econometrics. Princeton University Press. Abadie, A. (2005). Semiparametric difference-in-differences estimators. Review of Economic Studies, 72(1), 1–19. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. Wooldridge, J. M. (2010). Econometric Analysis of Cross Section and Panel Data. MIT Press. "],["causal-inference-in-practice-iv-instrumental-variables.html", "Chapter 5 Causal Inference in Practice IV: Instrumental Variables 5.1 Introduction 5.2 Healthcare Case Study: Hospital Quality and Recovery Time 5.3 Practical Considerations and Extensions 5.4 Conclusion 5.5 Further Reading", " Chapter 5 Causal Inference in Practice IV: Instrumental Variables 5.1 Introduction Imagine you’re a healthcare researcher trying to determine whether expensive, high-quality hospitals actually improve patient outcomes. The challenge? Patients don’t randomly choose hospitals—wealthier, more health-conscious patients often select premium facilities, making it nearly impossible to separate the hospital’s effect from patient characteristics you can’t measure. This is the fundamental problem of unmeasured confounding in observational studies. While methods like propensity score matching or Difference-in-Differences address specific scenarios, they rely on strong assumptions that often don’t hold when key confounders remain hidden. Instrumental Variables (IV) estimation offers a clever solution: it leverages exogenous variation—changes that occur “by chance” rather than by choice—to estimate causal effects even when important confounders are unmeasured. This guide explores IV methodology through a practical healthcare example: estimating how hospital quality affects patient recovery time. We’ll implement the method in R, verify key assumptions, and compare results with simpler approaches. By the end, you’ll understand when and how to apply IV estimation in your own research. Think of instrumental variables as nature’s randomized experiment. While we can’t randomly assign patients to hospitals, we can exploit factors that create “as good as random” variation in hospital choice. The key insight: if we find something that influences treatment assignment but doesn’t directly affect outcomes, we can use it to isolate the causal effect we’re interested in. Consider geographic proximity to high-quality hospitals. Patients living closer are more likely to choose these facilities, but distance itself shouldn’t affect recovery (assuming we control for other factors). This creates the variation we need for causal identification. A valid instrument must satisfy three critical conditions: Relevance (Instrument affects treatment): The instrument must meaningfully influence treatment assignment Mathematical condition: \\(\\text{Cov}(Z, D) \\neq 0\\) Practical test: First-stage F-statistic &gt; 10 Example: Distance to high-quality hospital affects hospital choice Exclusion Restriction (Instrument affects outcome only through treatment): The instrument cannot have direct pathways to the outcome Mathematical condition: \\(Y = f(D, X, \\varepsilon)\\) with \\(Z \\notin f\\) Practical consideration: Requires subject matter expertise and careful reasoning Example: Distance affects recovery only by influencing hospital choice, not through other channels Independence (Instrument is exogenous): The instrument must be uncorrelated with unmeasured confounders Mathematical condition: \\(Z \\perp \\{Y(1), Y(0)\\} \\mid X\\) Practical consideration: Often the most challenging assumption to defend Example: After controlling for observables, distance is unrelated to patient health consciousness Unlike randomized trials that estimate population-wide effects, IV identifies the Local Average Treatment Effect—the causal effect for “compliers,” individuals whose treatment status is influenced by the instrument. This is both a strength (we get unbiased causal estimates) and a limitation (results may not generalize to the full population). For binary instruments and treatments, the IV estimand is elegantly simple: \\[\\widehat{\\text{LATE}} = \\frac{\\mathbb{E}[Y \\mid Z = 1] - \\mathbb{E}[Y \\mid Z = 0]}{\\mathbb{E}[D \\mid Z = 1] - \\mathbb{E}[D \\mid Z = 0]}\\] This ratio scales the “reduced-form” effect (instrument → outcome) by the “first-stage” effect (instrument → treatment). The intuition: we divide the total effect of the instrument on outcomes by how much the instrument changes treatment uptake. When dealing with continuous variables or multiple covariates, we use Two-Stage Least Squares (2SLS): First Stage: Predict treatment using the instrument and controls \\[D_i = \\pi_0 + \\pi_1 Z_i + \\pi_2^\\top X_i + \\nu_i\\] Second Stage: Use predicted treatment values to estimate the causal effect \\[Y_i = \\alpha_0 + \\alpha_1 \\hat{D}_i + \\alpha_2^\\top X_i + \\varepsilon_i\\] The coefficient \\(\\alpha_1\\) provides our LATE estimate, robust to unmeasured confounding under valid IV assumptions. Method Assumption Effect Estimated Strengths Limitations IV Valid instrument LATE (compliers only) Handles unmeasured confounding Requires strong instrument; limited generalizability Propensity Scores Conditional ignorability ATE/ATT Intuitive; broad applicability Assumes all confounders observed Difference-in-Differences Parallel trends ATT Natural experiments Time-varying confounding issues 5.2 Healthcare Case Study: Hospital Quality and Recovery Time Objective: Estimate the causal effect of hospital quality on post-surgical recovery time Treatment: \\(D_i = 1\\) for high-quality hospitals, \\(D_i = 0\\) for standard hospitals Outcome: \\(Y_i\\) = recovery time in days (lower is better) Instrument: \\(Z_i = 1\\) if patient lives within 10 miles of a high-quality hospital The Confounding Problem: Patients choosing high-quality hospitals may differ systematically in unmeasured ways (health consciousness, social support, etc.) that also affect recovery. Assumption Verification Relevance: We expect proximity to strongly predict hospital choice. Patients prefer nearby facilities due to convenience, familiarity, and reduced travel burden. Exclusion Restriction: Distance affects recovery only through hospital choice, not via: - Local healthcare infrastructure quality - Air quality or environmental factors - Socioeconomic clustering (controlled for through observables) Independence: After controlling for income, education, and urban/rural status, proximity should be uncorrelated with unmeasured health behaviors. 5.2.1 R Implementation Let’s implement IV estimation with simulated data that mirrors real-world healthcare scenarios: # Load required packages if (!requireNamespace(&quot;AER&quot;, quietly = TRUE)) install.packages(&quot;AER&quot;) if (!requireNamespace(&quot;ggplot2&quot;, quietly = TRUE)) install.packages(&quot;ggplot2&quot;) if (!requireNamespace(&quot;dplyr&quot;, quietly = TRUE)) install.packages(&quot;dplyr&quot;) library(AER) library(ggplot2) library(dplyr) # Set parameters for reproducible simulation set.seed(123) n &lt;- 1000 # Sample size p &lt;- 5 # Number of covariates # Generate realistic patient characteristics X &lt;- matrix(rnorm(n * p), nrow = n) colnames(X) &lt;- c(&quot;age&quot;, &quot;income&quot;, &quot;education&quot;, &quot;comorbidities&quot;, &quot;urban&quot;) # Instrument: Geographic proximity (exogenous after controlling for observables) proximity_prob &lt;- plogis(-0.5 + 0.3 * X[, &quot;urban&quot;] + 0.1 * X[, &quot;income&quot;]) Z &lt;- rbinom(n, 1, proximity_prob) # Treatment: Hospital choice (influenced by proximity and patient characteristics) # Strong first stage ensures instrument relevance hospital_choice_prob &lt;- plogis(-0.5 + 1.2 * Z + 0.3 * X[, &quot;income&quot;] + 0.2 * X[, &quot;education&quot;] + 0.1 * X[, &quot;urban&quot;]) D &lt;- rbinom(n, 1, hospital_choice_prob) # Outcome: Recovery time with unmeasured confounding # Unmeasured confounder: health consciousness (affects both hospital choice and recovery) health_consciousness &lt;- rnorm(n, mean = 0.2 * X[, &quot;education&quot;] + 0.1 * X[, &quot;income&quot;]) # True causal effect: -4 days for high-quality hospitals true_late &lt;- -4 recovery_time &lt;- 25 + true_late * D + 2 * X[, &quot;age&quot;] + 1.5 * X[, &quot;comorbidities&quot;] + 2 * health_consciousness + # Unmeasured confounder rnorm(n, sd = 3) # Create analysis dataset data &lt;- data.frame( recovery_time = recovery_time, hospital_quality = D, proximity = Z, age = X[, &quot;age&quot;], income = X[, &quot;income&quot;], education = X[, &quot;education&quot;], comorbidities = X[, &quot;comorbidities&quot;], urban = X[, &quot;urban&quot;] ) # Step 1: Check instrument relevance (First Stage) first_stage &lt;- lm(hospital_quality ~ proximity + age + income + education + comorbidities + urban, data = data) first_stage_summary &lt;- summary(first_stage) f_stat &lt;- first_stage_summary$fstatistic[1] cat(&quot;=== FIRST STAGE DIAGNOSTICS ===\\n&quot;) ## === FIRST STAGE DIAGNOSTICS === cat(&quot;First-stage F-statistic:&quot;, round(f_stat, 2), &quot;\\n&quot;) ## First-stage F-statistic: 19.19 cat(&quot;Rule of thumb: F &gt; 10 indicates strong instrument\\n&quot;) ## Rule of thumb: F &gt; 10 indicates strong instrument cat(&quot;Proximity coefficient:&quot;, round(coef(first_stage)[&quot;proximity&quot;], 3), &quot;\\n&quot;) ## Proximity coefficient: 0.241 cat(&quot;P-value:&quot;, round(coef(first_stage_summary)[&quot;proximity&quot;, &quot;Pr(&gt;|t|)&quot;], 4), &quot;\\n\\n&quot;) ## P-value: 0 # Step 2: Two-Stage Least Squares estimation iv_model &lt;- ivreg(recovery_time ~ hospital_quality + age + income + education + comorbidities + urban | proximity + age + income + education + comorbidities + urban, data = data) iv_summary &lt;- summary(iv_model) # Step 3: Wald estimator (simple version without covariates) reduced_form &lt;- lm(recovery_time ~ proximity, data = data) first_stage_simple &lt;- lm(hospital_quality ~ proximity, data = data) wald_estimate &lt;- coef(reduced_form)[&quot;proximity&quot;] / coef(first_stage_simple)[&quot;proximity&quot;] # Step 4: Naive OLS (biased due to unmeasured confounding) ols_model &lt;- lm(recovery_time ~ hospital_quality + age + income + education + comorbidities + urban, data = data) # Display results cat(&quot;=== ESTIMATION RESULTS ===\\n&quot;) ## === ESTIMATION RESULTS === cat(&quot;True LATE (simulation parameter):&quot;, true_late, &quot;days\\n&quot;) ## True LATE (simulation parameter): -4 days cat(&quot;2SLS estimate:&quot;, round(coef(iv_summary)[&quot;hospital_quality&quot;, &quot;Estimate&quot;], 2), &quot;days\\n&quot;) ## 2SLS estimate: -4.78 days cat(&quot;2SLS standard error:&quot;, round(coef(iv_summary)[&quot;hospital_quality&quot;, &quot;Std. Error&quot;], 2), &quot;\\n&quot;) ## 2SLS standard error: 1.01 cat(&quot;Wald estimate:&quot;, round(wald_estimate, 2), &quot;days\\n&quot;) ## Wald estimate: -4.53 days cat(&quot;Naive OLS estimate:&quot;, round(coef(ols_model)[&quot;hospital_quality&quot;], 2), &quot;days\\n\\n&quot;) ## Naive OLS estimate: -3.83 days # Create visualization estimates_df &lt;- data.frame( Method = c(&quot;2SLS&quot;, &quot;Wald&quot;, &quot;OLS&quot;, &quot;True LATE&quot;), Estimate = c( coef(iv_summary)[&quot;hospital_quality&quot;, &quot;Estimate&quot;], wald_estimate, coef(ols_model)[&quot;hospital_quality&quot;], true_late ), SE = c( coef(iv_summary)[&quot;hospital_quality&quot;, &quot;Std. Error&quot;], NA, summary(ols_model)$coefficients[&quot;hospital_quality&quot;, &quot;Std. Error&quot;], NA ) ) %&gt;% mutate( Lower = Estimate - 1.96 * SE, Upper = Estimate + 1.96 * SE, Color = case_when( Method == &quot;True LATE&quot; ~ &quot;Truth&quot;, Method %in% c(&quot;2SLS&quot;, &quot;Wald&quot;) ~ &quot;IV Methods&quot;, TRUE ~ &quot;Biased&quot; ) ) # Enhanced visualization ggplot(estimates_df, aes(x = Method, y = Estimate, fill = Color)) + geom_col(alpha = 0.7, width = 0.6) + geom_errorbar(aes(ymin = Lower, ymax = Upper), width = 0.2, color = &quot;black&quot;, na.rm = TRUE) + geom_hline(yintercept = true_late, linetype = &quot;dashed&quot;, color = &quot;red&quot;, size = 1) + scale_fill_manual(values = c(&quot;IV Methods&quot; = &quot;#2E86AB&quot;, &quot;Biased&quot; = &quot;#A23B72&quot;, &quot;Truth&quot; = &quot;#F18F01&quot;)) + labs( title = &quot;Hospital Quality Effect on Recovery Time&quot;, subtitle = &quot;Comparison of estimation methods with 95% confidence intervals&quot;, y = &quot;Effect on Recovery Time (Days)&quot;, x = &quot;Estimation Method&quot;, fill = &quot;Method Type&quot;, caption = &quot;Dashed line shows true causal effect&quot; ) + theme_minimal() + theme( plot.title = element_text(size = 14, face = &quot;bold&quot;), axis.text.x = element_text(angle = 45, hjust = 1), legend.position = &quot;bottom&quot; ) 5.2.2 Interpreting the Results First-Stage Strength: The F-statistic tests instrument relevance. Values above 10 indicate a strong instrument; above 20 is considered very strong. Weak instruments (F &lt; 10) lead to biased and imprecise estimates. Estimate Comparison: In our simulation: - 2SLS should recover the true LATE (-4 days) with appropriate uncertainty - Wald estimator provides similar point estimates but may be less precise without covariate adjustment - Naive OLS typically shows bias toward zero due to unmeasured confounding The 2SLS coefficient represents the LATE: the expected reduction in recovery time for patients whose hospital choice is influenced by proximity. This effect applies specifically to “compliers”—patients who would choose high-quality hospitals when living nearby but standard hospitals when living far away. Confidence intervals reflect estimation uncertainty. Wide intervals may indicate weak instruments, small sample sizes, or high outcome variability. Common Threats to Validity Weak Instruments: Low first-stage F-statistics indicate insufficient variation in treatment driven by the instrument Exclusion Restriction Violations: Distance might affect recovery through: Proximity to other medical facilities Socioeconomic sorting by geography Environmental factors correlated with location Independence Violations: Systematic differences between near/far patients in unmeasured characteristics 5.2.3 Robustness Checks # Additional diagnostic: Examine balance on observables cat(&quot;=== BALANCE CHECK ===\\n&quot;) ## === BALANCE CHECK === balance_test &lt;- t.test(data$income[data$proximity == 1], data$income[data$proximity == 0]) cat(&quot;Income difference by proximity (p-value):&quot;, round(balance_test$p.value, 3), &quot;\\n&quot;) ## Income difference by proximity (p-value): 0 # Examine complier population size complier_share &lt;- (mean(data$hospital_quality[data$proximity == 1]) - mean(data$hospital_quality[data$proximity == 0])) cat(&quot;Estimated complier share:&quot;, round(complier_share * 100, 1), &quot;%\\n&quot;) ## Estimated complier share: 26.7 % 5.3 Practical Considerations and Extensions 5.3.1 When to Use IV Ideal scenarios: - Strong theoretical justification for instrument validity - Unmeasured confounding is suspected - Natural experiments or policy discontinuities create exogenous variation Proceed with caution when: - Instruments are weak (F &lt; 10) - Exclusion restriction is questionable - Treatment effects are highly heterogeneous 5.3.2 Advanced Topics Multiple instruments: Hansen J-test for overidentification Continuous treatments: Linear IV models with interpretation caveats Machine learning: Regularized IV with many instruments Heterogeneous effects: Marginal Treatment Effects framework 5.4 Conclusion Instrumental Variables estimation provides a powerful approach for causal inference when unmeasured confounding threatens validity. Through our healthcare example, we’ve seen how geographic proximity can serve as an instrument to estimate hospital quality effects on recovery time. The method’s strength lies in its ability to handle hidden bias, but this comes with important trade-offs: the need for valid instruments and interpretation limited to complier populations. Success depends critically on careful instrument selection, thorough assumption verification, and honest assessment of potential violations. When applied thoughtfully with domain expertise, IV estimation can reveal causal relationships that would otherwise remain hidden in observational data, making it an invaluable tool for researchers tackling complex real-world questions. 5.5 Further Reading Angrist, J. D., &amp; Pischke, J.-S. (2009). Mostly Harmless Econometrics: An Empiricist’s Companion. Princeton University Press. Hernán, M. A., &amp; Robins, J. M. (2020). Causal Inference: What If. Chapman &amp; Hall/CRC. Imbens, G. W., &amp; Rubin, D. B. (2015). Causal Inference for Statistics, Social, and Biomedical Sciences. Cambridge University Press. "],["causal-inference-in-practice-v-regression-discontinuity-design.html", "Chapter 6 Causal Inference in Practice V: Regression Discontinuity Design 6.1 Introduction 6.2 Healthcare Application: ICU Admission and Mortality 6.3 Interpretation and Diagnostics 6.4 Extensions and Robustness 6.5 Limitations and Considerations 6.6 Conclusion 6.7 References", " Chapter 6 Causal Inference in Practice V: Regression Discontinuity Design 6.1 Introduction Regression Discontinuity Design (RDD) exploits arbitrary thresholds in treatment assignment to identify causal effects in observational data. Unlike other causal inference methods that rely on assumptions about unobserved confounders or parallel trends, RDD leverages the fact that treatment assignment changes discontinuously at a known cutoff point while potential outcomes vary smoothly. This creates a quasi-experimental setting where units just above and below the threshold are comparable, except for their treatment status, enabling credible causal inference even when randomized experiments are infeasible. The method proves particularly valuable in policy evaluation contexts where treatments are assigned based on arbitrary cutoffs, such as scholarship eligibility based on test scores, medical interventions based on diagnostic thresholds, or regulatory compliance based on firm size. This essay examines RDD’s theoretical foundation, mathematical framework, and practical implementation through a healthcare application estimating the causal effect of intensive care unit admission on patient mortality using simulated data in R. We explore both sharp and fuzzy designs, discuss assumption validation, and compare RDD with alternative causal inference approaches. RDD identification relies on the assumption that potential outcomes are continuous functions of a running variable at the treatment cutoff, while treatment assignment exhibits a discontinuity. Consider a running variable X with cutoff c, where treatment D = 1 if X ≥ c and D = 0 if X &lt; c. The key insight is that units with X values arbitrarily close to c are similar in all respects except treatment status, making the cutoff a source of quasi-random variation. RDD applies when treatment assignment follows a deterministic rule based on an observed running variable \\(X\\): \\[ D_i = \\begin{cases} 1 &amp; \\text{if } X_i \\geq c \\\\ 0 &amp; \\text{if } X_i &lt; c \\end{cases} \\] where \\(c\\) represents the cutoff threshold. This sharp discontinuity contrasts with fuzzy RDD, where the assignment rule creates jumps in treatment probability rather than certainty. The key insight: individuals near the cutoff are exchangeable. The RDD estimand targets the treatment effect at the cutoff: \\[ \\tau_{RDD} = \\mathbb{E}[Y_i(1) - Y_i(0) | X_i = c] \\] Since we observe only one potential outcome for each unit, identification requires continuity of the conditional expectation function at the cutoff. Formally: \\[ \\mathbb{E}[Y_i(0) | X_i = x] \\text{ and } \\mathbb{E}[Y_i(1) | X_i = x] \\text{ are continuous at } x = c \\] When this holds, the treatment effect equals the discontinuous jump in the observed outcome: \\[ \\tau_{RDD} = \\lim_{x \\to c^+} \\mathbb{E}[Y_i | X_i = x] - \\lim_{x \\to c^-} \\mathbb{E}[Y_i | X_i = x] \\] The identifying assumption is continuity of potential outcomes at the cutoff. Formally, for potential outcomes Y(0) and Y(1) under control and treatment, the expected values of both potential outcomes must be continuous at the cutoff point. Under this assumption, the treatment effect at the cutoff is identified by the discontinuity in the observed outcome. This local average treatment effect (LATE) applies specifically to units at the cutoff, representing the causal effect for individuals with running variable values equal to the threshold. Sharp RDD occurs when treatment assignment is a deterministic function of the running variable, with probability of treatment jumping from 0 to 1 at the cutoff. The treatment effect is estimated directly from the outcome discontinuity. Fuzzy RDD arises when treatment probability changes discontinuously but not deterministically at the cutoff, creating a first-stage relationship between the running variable and treatment assignment. Fuzzy designs require two-stage estimation similar to instrumental variables, where the cutoff serves as an instrument for treatment receipt. For fuzzy designs, the treatment effect is calculated as the ratio of the outcome discontinuity to the treatment probability discontinuity, analogous to the Wald estimator in instrumental variables estimation. RDD estimation typically employs local polynomial regression focusing on observations near the cutoff. The parametric approach fits separate polynomials on each side of the threshold, where the treatment effect is captured by the coefficient on the treatment indicator. The nonparametric approach uses local linear regression with kernel weights, estimating separate regressions on each side of the cutoff using observations within a bandwidth h of the threshold. Bandwidth selection involves a bias-variance tradeoff. Smaller bandwidths reduce bias by focusing on units most similar to those at the cutoff but increase variance due to smaller sample sizes. Optimal bandwidth selection procedures balance these considerations using cross-validation or mean squared error criteria. 6.1.1 Comparison with Other Methods RDD differs fundamentally from other causal inference approaches in its identification strategy and assumptions. Unlike instrumental variables, which require exogenous instruments affecting treatment but not outcomes directly, RDD uses the cutoff itself as a source of variation, requiring only continuity of potential outcomes. Compared to difference-in-differences, which relies on parallel trends assumptions and requires panel data, RDD can be applied to cross-sectional data and identifies effects through spatial rather than temporal variation. The method’s strength lies in its credibility when assignment rules are truly arbitrary and discontinuous. However, RDD provides only local identification at the cutoff, limiting external validity compared to methods estimating population-wide effects. The approach also requires sufficient observations near the threshold for precise estimation and may be sensitive to functional form misspecification in parametric implementations. 6.2 Healthcare Application: ICU Admission and Mortality 6.2.1 Scenario We examine the causal effect of intensive care unit admission on 30-day mortality risk for emergency department patients. Many hospitals use severity scores with specific cutoffs to guide ICU admission decisions. Patients with scores above the threshold receive intensive monitoring and treatment, while those below receive standard ward care. This creates a sharp discontinuity in treatment assignment that enables causal inference about ICU effectiveness. The running variable is the Acute Physiology and Chronic Health Evaluation (APACHE) score, with ICU admission mandated for scores of 15 or higher. The outcome is 30-day mortality, coded as 1 for death within 30 days and 0 for survival. The key assumption is that patient mortality risk varies smoothly with APACHE scores, while ICU admission probability jumps discontinuously at the cutoff. 6.2.2 Assumptions and Validity The primary identifying assumption requires potential outcomes to be continuous at the cutoff. This seems plausible since APACHE scores reflect underlying health status, which should vary smoothly rather than discontinuously. However, gaming or manipulation around the cutoff could violate this assumption if physicians systematically adjust scores to influence admission decisions. Several empirical tests can assess assumption validity. Density tests examine whether the running variable distribution exhibits suspicious clustering around the cutoff. Continuity tests check whether predetermined covariates show discontinuities at the threshold. Placebo tests estimate effects at false cutoffs where no treatment discontinuity exists. These diagnostics help build confidence in the design’s credibility. 6.2.3 R Implementation We simulate data for 2000 emergency department patients with APACHE scores ranging from 10 to 20. The true treatment effect is a 15 percentage point reduction in mortality risk for ICU patients at the cutoff. Our implementation includes both parametric and nonparametric estimation approaches. # Load required libraries if (!requireNamespace(&quot;rdrobust&quot;, quietly = TRUE)) install.packages(&quot;rdrobust&quot;) if (!requireNamespace(&quot;ggplot2&quot;, quietly = TRUE)) install.packages(&quot;ggplot2&quot;) if (!requireNamespace(&quot;dplyr&quot;, quietly = TRUE)) install.packages(&quot;dplyr&quot;) library(rdrobust) library(ggplot2) library(dplyr) # Set seed for reproducibility set.seed(456) # Simulate data n &lt;- 2000 cutoff &lt;- 15 # Running variable: APACHE score (10-20) apache_score &lt;- runif(n, 10, 20) # Treatment: ICU admission (sharp design) icu_admission &lt;- as.numeric(apache_score &gt;= cutoff) # Baseline mortality risk (smooth function of APACHE score) baseline_risk &lt;- 0.1 + 0.03 * (apache_score - 15) + 0.001 * (apache_score - 15)^2 # True treatment effect: -0.15 (15 percentage point reduction) true_effect &lt;- -0.15 mortality_prob &lt;- baseline_risk + true_effect * icu_admission # Add random noise and generate binary outcome mortality_prob &lt;- pmax(0, pmin(1, mortality_prob + rnorm(n, 0, 0.05))) mortality &lt;- rbinom(n, 1, mortality_prob) # Create dataset data &lt;- data.frame( apache_score = apache_score, icu_admission = icu_admission, mortality = mortality, centered_score = apache_score - cutoff ) # Parametric estimation with local linear regression param_model &lt;- lm(mortality ~ icu_admission + centered_score + I(centered_score * icu_admission), data = data) param_effect &lt;- coef(param_model)[&quot;icu_admission&quot;] param_se &lt;- summary(param_model)$coefficients[&quot;icu_admission&quot;, &quot;Std. Error&quot;] cat(&quot;Parametric RDD estimate:&quot;, round(param_effect, 4), &quot;\\n&quot;) cat(&quot;Standard error:&quot;, round(param_se, 4), &quot;\\n&quot;) # Nonparametric estimation using rdrobust rd_result &lt;- rdrobust(y = data$mortality, x = data$apache_score, c = cutoff) nonparam_effect &lt;- rd_result$coef[&quot;Robust&quot;, ] nonparam_se &lt;- rd_result$se[&quot;Robust&quot;, ] optimal_bandwidth &lt;- rd_result$bws[&quot;h&quot;, &quot;left&quot;] cat(&quot;Nonparametric RDD estimate:&quot;, round(nonparam_effect, 4), &quot;\\n&quot;) cat(&quot;Robust standard error:&quot;, round(nonparam_se, 4), &quot;\\n&quot;) cat(&quot;Optimal bandwidth:&quot;, round(optimal_bandwidth, 2), &quot;\\n&quot;) # Placebo test at false cutoff false_cutoff &lt;- 13 placebo_result &lt;- rdrobust(y = data$mortality, x = data$apache_score, c = false_cutoff) placebo_effect &lt;- placebo_result$coef[&quot;Robust&quot;, ] placebo_se &lt;- placebo_result$se[&quot;Robust&quot;, ] cat(&quot;Placebo test estimate:&quot;, round(placebo_effect, 4), &quot;\\n&quot;) cat(&quot;Placebo test p-value:&quot;, round(2 * (1 - pnorm(abs(placebo_effect / placebo_se))), 4), &quot;\\n&quot;) # Visualization # Create prediction data for smooth curves pred_data &lt;- data.frame(apache_score = seq(10, 20, 0.1)) pred_data$centered_score &lt;- pred_data$apache_score - cutoff pred_data$icu_admission &lt;- as.numeric(pred_data$apache_score &gt;= cutoff) # Separate models for each side left_model &lt;- lm(mortality ~ centered_score, data = data[data$apache_score &lt; cutoff, ]) right_model &lt;- lm(mortality ~ centered_score, data = data[data$apache_score &gt;= cutoff, ]) pred_left &lt;- predict(left_model, newdata = pred_data[pred_data$apache_score &lt; cutoff, ], se.fit = TRUE) pred_right &lt;- predict(right_model, newdata = pred_data[pred_data$apache_score &gt;= cutoff, ], se.fit = TRUE) # Combine predictions plot_data &lt;- data.frame( apache_score = c(pred_data$apache_score[pred_data$apache_score &lt; cutoff], pred_data$apache_score[pred_data$apache_score &gt;= cutoff]), predicted = c(pred_left$fit, pred_right$fit), se = c(pred_left$se.fit, pred_right$se.fit), side = c(rep(&quot;Control&quot;, sum(pred_data$apache_score &lt; cutoff)), rep(&quot;Treatment&quot;, sum(pred_data$apache_score &gt;= cutoff))) ) plot_data$lower &lt;- plot_data$predicted - 1.96 * plot_data$se plot_data$upper &lt;- plot_data$predicted + 1.96 * plot_data$se # Create binned scatter plot bin_data &lt;- data %&gt;% mutate(bin = round(apache_score * 2) / 2) %&gt;% group_by(bin) %&gt;% summarise(mean_mortality = mean(mortality), se_mortality = sd(mortality) / sqrt(n()), .groups = &#39;drop&#39;) %&gt;% filter(bin &gt;= 12 &amp; bin &lt;= 18) # Main plot p1 &lt;- ggplot() + geom_point(data = bin_data, aes(x = bin, y = mean_mortality), alpha = 0.7, size = 2) + geom_errorbar(data = bin_data, aes(x = bin, ymin = mean_mortality - 1.96 * se_mortality, ymax = mean_mortality + 1.96 * se_mortality), width = 0.1, alpha = 0.7) + geom_line(data = plot_data, aes(x = apache_score, y = predicted, color = side), size = 1.2) + geom_ribbon(data = plot_data, aes(x = apache_score, ymin = lower, ymax = upper, fill = side), alpha = 0.2) + geom_vline(xintercept = cutoff, linetype = &quot;dashed&quot;, color = &quot;red&quot;, size = 1) + scale_color_manual(values = c(&quot;Control&quot; = &quot;#1f77b4&quot;, &quot;Treatment&quot; = &quot;#ff7f0e&quot;)) + scale_fill_manual(values = c(&quot;Control&quot; = &quot;#1f77b4&quot;, &quot;Treatment&quot; = &quot;#ff7f0e&quot;)) + labs(title = &quot;RDD: Effect of ICU Admission on 30-Day Mortality&quot;, x = &quot;APACHE Score&quot;, y = &quot;30-Day Mortality Rate&quot;, color = &quot;Treatment Status&quot;, fill = &quot;Treatment Status&quot;) + theme_minimal() + theme(legend.position = &quot;bottom&quot;) + annotate(&quot;text&quot;, x = cutoff + 0.5, y = 0.25, label = paste(&quot;ICU Cutoff\\n(Score ≥&quot;, cutoff, &quot;)&quot;), color = &quot;red&quot;, size = 3) print(p1) # Results summary results &lt;- data.frame( Method = c(&quot;Parametric&quot;, &quot;Nonparametric&quot;, &quot;Placebo Test&quot;), Estimate = c(param_effect, nonparam_effect, placebo_effect), SE = c(param_se, nonparam_se, placebo_se), Lower_CI = c(param_effect - 1.96 * param_se, nonparam_effect - 1.96 * nonparam_se, placebo_effect - 1.96 * placebo_se), Upper_CI = c(param_effect + 1.96 * param_se, nonparam_effect + 1.96 * nonparam_se, placebo_effect + 1.96 * placebo_se) ) print(results) # Effect size interpretation cat(&quot;\\nInterpretation:\\n&quot;) cat(&quot;True effect:&quot;, true_effect, &quot;(15 percentage point reduction)\\n&quot;) cat(&quot;Parametric estimate suggests&quot;, round(abs(param_effect) * 100, 1), &quot;percentage point reduction in mortality\\n&quot;) cat(&quot;Nonparametric estimate suggests&quot;, round(abs(nonparam_effect) * 100, 1), &quot;percentage point reduction in mortality\\n&quot;) 6.3 Interpretation and Diagnostics The parametric and nonparametric estimates should approximate the true treatment effect of -0.15 if the design assumptions hold. The optimal bandwidth determined by the rdrobust package balances bias and variance considerations, typically including observations within 1-3 units of the cutoff. Confidence intervals reflect estimation uncertainty, with nonparametric approaches often producing wider intervals due to their flexibility. The density test examines whether the running variable distribution shows evidence of manipulation around the cutoff. A significant test statistic suggests systematic sorting that could invalidate the design. In our simulation, the p-value should exceed conventional significance levels since we generated random APACHE scores without manipulation. The placebo test estimates effects at a false cutoff where no treatment discontinuity exists. Significant placebo effects suggest that observed discontinuities may reflect underlying trends rather than treatment effects, casting doubt on the main results. Successful placebo tests show estimates close to zero with insignificant p-values. Visual inspection provides additional validation. The plot should show smooth outcome trends on both sides of the cutoff with a clear discontinuity at the threshold. Binned scatter plots help reveal the underlying relationship while reducing noise from individual observations. Suspicious patterns, such as unusual curvature near the cutoff or multiple discontinuities, warrant further investigation. 6.4 Extensions and Robustness RDD can be extended in several directions to enhance robustness and applicability. Multiple cutoffs designs exploit variation from several thresholds to improve precision and test assumption validity across different cutoff values. Geographic regression discontinuity uses spatial boundaries as cutoffs, identifying effects of policies that vary across jurisdictions. Dynamic RDD examines how treatment effects evolve over time when cutoffs change. Robustness checks assess sensitivity to key modeling choices. Bandwidth sensitivity tests examine how estimates change across different window sizes around the cutoff. Functional form tests compare linear, quadratic, and higher-order specifications to check parametric assumptions. Donut RDD excludes observations immediately around the cutoff to test for manipulation or measurement error effects. When compliance with treatment assignment is imperfect, fuzzy RDD designs require additional assumptions similar to instrumental variables. The exclusion restriction requires that crossing the cutoff affects outcomes only through changing treatment probability, not through other channels. Monotonicity assumes that crossing the cutoff never decreases treatment probability for any individual. 6.5 Limitations and Considerations RDD faces several important limitations that researchers must consider. The method provides only local identification at the cutoff, limiting external validity to the broader population. Treatment effects may vary systematically across the running variable distribution, making cutoff-specific estimates unrepresentative of population-wide effects. This is particularly problematic when policy interest focuses on average treatment effects rather than local effects. Sample size requirements can be substantial, especially for nonparametric approaches that rely on observations near the cutoff. Power calculations suggest that RDD typically requires 2-3 times larger samples than randomized experiments to achieve comparable precision. This constraint may limit feasibility in settings with small samples or rare outcomes. Functional form misspecification poses risks in parametric implementations. Higher-order polynomials can create spurious discontinuities through overfitting, while overly restrictive specifications may mask true effects through bias. Nonparametric approaches mitigate these concerns but require careful bandwidth selection and may suffer from boundary bias near the cutoff. The method assumes precise measurement of the running variable and knowledge of the exact cutoff value. Measurement error in the running variable can attenuate estimates, while uncertainty about cutoff locations complicates interpretation. These issues are particularly relevant in settings with multiple decision-makers or evolving assignment rules. 6.6 Conclusion Regression Discontinuity Design offers a credible approach to causal inference when treatment assignment follows arbitrary cutoff rules. The method’s strength lies in its minimal assumptions and high internal validity near the threshold, making it particularly valuable for policy evaluation in healthcare, education, and other domains with rule-based allocation mechanisms. Our healthcare application demonstrates practical implementation using both parametric and nonparametric approaches, highlighting the importance of assumption testing and robustness checks. While RDD provides only local identification and may require large samples for precise estimation, its quasi-experimental nature often makes it preferable to approaches requiring stronger assumptions about selection or confounding. The method continues to evolve through methodological advances in bandwidth selection, inference procedures, and extension to more complex designs. Future research directions include integration with machine learning methods for improved flexibility and the development of approaches for settings with fuzzy or time-varying cutoffs. Successful RDD implementation requires careful attention to institutional details, thorough assumption validation, and transparent reporting of robustness checks. When these conditions are met, the design provides compelling evidence for causal effects that can inform policy decisions and advance scientific understanding in contexts where randomized experiments remain infeasible. 6.7 References Lee, D. S., &amp; Lemieux, T. (2010). Regression discontinuity designs in economics. Journal of Economic Literature, 48(2), 281-355. Imbens, G., &amp; Kalyanaraman, K. (2012). Optimal bandwidth choice for the regression discontinuity estimator. Review of Economic Studies, 79(3), 933-959. Calonico, S., Cattaneo, M. D., &amp; Titiunik, R. (2014). Robust nonparametric confidence intervals for regression-discontinuity designs. Econometrica, 82(6), 2295-2326. Cattaneo, M. D., Idrobo, N., &amp; Titiunik, R. (2019). A Practical Introduction to Regression Discontinuity Designs: Foundations. Cambridge University Press. "],["causal-inference-in-practice-vi-causal-forests.html", "Chapter 7 Causal Inference in Practice VI: Causal Forests 7.1 Introduction 7.2 Theoretical Framework and Methodology 7.3 Application: Personalized Diabetes Treatment 7.4 Conclusion", " Chapter 7 Causal Inference in Practice VI: Causal Forests 7.1 Introduction The evaluation of interventions, from clinical trials of new pharmaceuticals to the implementation of social programs, has traditionally focused on estimating the Average Treatment Effect (ATE). The ATE provides a single, population-level measure of an intervention’s impact. However, this focus on the average response can be misleading, as the assumption of a constant treatment effect across all individuals is often violated. In reality, the efficacy of a treatment may vary systematically with individual characteristics, a phenomenon known as treatment effect heterogeneity. Identifying which individuals benefit most, least, or are even harmed by an intervention is crucial for developing personalized policies and precision medicine. Traditional parametric models, such as linear regression with interaction terms, are limited in this endeavor as they require a priori specification of the functional form of the heterogeneity. This pre-specification risks model misspecification and fails to capture complex, non-linear patterns of effect modification. Machine learning methods, particularly tree-based ensemble methods, offer a powerful alternative for uncovering complex data structures without pre-specification. The causal forest, introduced by Wager and Athey (2018), adapts the random forest algorithm to the specific task of estimating the Conditional Average Treatment Effect (CATE), \\(\\\\tau(x)\\), which is the treatment effect for a subpopulation defined by a vector of covariates \\(x\\). The method’s key innovation is a splitting criterion that partitions the data to maximize the heterogeneity in treatment effects between child nodes. Furthermore, by incorporating a technique known as “honesty” or sample-splitting, causal forests can provide asymptotically unbiased estimates of the CATE and valid confidence intervals, addressing a common shortcoming of applying standard machine learning algorithms to causal inference tasks. This paper provides a formal overview of the causal forest methodology. We begin by establishing the theoretical framework, including the potential outcomes model and the identifying assumptions. We then describe the algorithm’s mechanics, focusing on the splitting rule and the honesty principle that ensures valid inference. Finally, we present a comprehensive application using simulated data from a clinical trial to demonstrate how causal forests can be used to guide personalized treatment decisions. 7.2 Theoretical Framework and Methodology 7.2.1 Potential Outcomes and Identifying Assumptions The foundation of the causal forest methodology rests on the potential outcomes framework (Neyman, 1923; Rubin, 1974). For each individual \\(i\\) in a population of size \\(n\\), let \\(X\\_i\\) be a vector of pre-treatment covariates. Let \\(W\\_i \\\\in {0, 1}\\) be an indicator for treatment assignment, where \\(W\\_i=1\\) denotes assignment to the treatment group and \\(W\\_i=0\\) denotes assignment to the control group. Each individual has two potential outcomes: \\(Y\\_i(1)\\), the outcome if the individual receives the treatment, and \\(Y\\_i(0)\\), the outcome if the individual does not. The individual treatment effect is defined as \\(\\\\tau\\_i = Y\\_i(1) - Y\\_i(0)\\). The fundamental problem of causal inference is that for any given individual, only one of the two potential outcomes is observed. The observed outcome, \\(Y\\_i\\), is given by \\(Y\\_i = W\\_i Y\\_i(1) + (1 - W\\_i) Y\\_i(0)\\). Our primary object of interest is the Conditional Average Treatment Effect (CATE), defined as the expected treatment effect for individuals with covariates \\(X\\_i = x\\): \\[\\tau(x) = \\mathbb{E}[Y_i(1) - Y_i(0) | X_i = x]\\] To identify \\(\\\\tau(x)\\) from observed data, we rely on three standard assumptions: Unconfoundedness (or Ignorability): Conditional on the covariates \\(X\\_i\\), the treatment assignment \\(W\\_i\\) is independent of the potential outcomes. Formally, \\({Y\\_i(1), Y\\_i(0)} \\\\perp W\\_i | X\\_i\\). This assumption implies that there are no unobserved variables that are associated with both treatment assignment and the potential outcomes. In a randomized controlled trial, this assumption holds by design. Overlap (or Positivity): For all values of \\(x\\) in the support of \\(X\\), the probability of receiving treatment is strictly between 0 and 1. Let the propensity score be \\(e(x) = \\\\mathbb{P}(W\\_i = 1 | X\\_i = x)\\). The overlap assumption requires \\(0 \\&lt; e(x) \\&lt; 1\\). This ensures that for any subgroup defined by \\(x\\), there are both treated and control units, making comparisons possible. Stable Unit Treatment Value Assumption (SUTVA): This assumption states that there is no interference between units (the potential outcomes of one individual are unaffected by the treatment status of others) and that there are no hidden variations of the treatment. Under these assumptions, the CATE can be identified from the observed data: \\[\\tau(x) = \\mathbb{E}[Y_i | W_i=1, X_i=x] - \\mathbb{E}[Y_i | W_i=0, X_i=x]\\] 7.2.2 The Causal Forest Algorithm A causal forest is an ensemble of causal trees. While a standard regression tree seeks to partition the data to minimize prediction error (e.g., mean squared error), a causal tree partitions the data to maximize the heterogeneity in the treatment effect. Consider a parent node \\(S\\) and a proposed split into two child nodes, \\(S\\_L\\) and \\(S\\_R\\). A standard causal tree algorithm seeks to find the split that maximizes the following criterion: \\[\\Delta(S, S_L, S_R) = |S_L| \\cdot (\\hat{\\tau}(S_L) - \\hat{\\tau}(S))^2 + |S_R| \\cdot (\\hat{\\tau}(S_R) - \\hat{\\tau}(S))^2\\] where \\(\\\\hat{\\\\tau}(S)\\) is the estimated treatment effect within the set of observations \\(S\\), typically calculated as the simple difference-in-means between treated and control units within that set. This criterion prioritizes splits that create children whose treatment effects are maximally different from their parent’s, thereby isolating pockets of heterogeneity. A key feature ensuring valid statistical inference is honesty. In an honest estimation scheme, the data is split into two independent subsamples. The first subsample, the splitting sample, is used to build the structure of each tree (i.e., to determine the sequence of splits). The second subsample, the estimation sample, is then used to populate the terminal leaves of the constructed tree and to estimate the treatment effects within those leaves. This separation prevents the same data from being used for both model selection (finding the best splits) and estimation, which mitigates overfitting and allows for the construction of asymptotically valid confidence intervals. 7.2.3 Estimation and Inference Once a forest of \\(B\\) honest causal trees is grown, a prediction for a new test point \\(x\\) is made by aggregating information from all trees. For each tree \\(b \\\\in {1, ..., B}\\), the test point \\(x\\) falls into a specific terminal leaf, \\(L\\_b(x)\\). The CATE estimate, \\(\\\\hat{\\\\tau}(x)\\), is a weighted average of the outcomes of the training samples, where the weights depend on how often a training sample \\(i\\) falls into the same leaf as the test point \\(x\\). The weight that the observation \\(i\\) receives for the prediction at point \\(x\\), \\(\\\\alpha\\_i(x)\\), is defined as: \\[\\alpha_i(x) = \\frac{1}{B} \\sum_{b=1}^{B} \\frac{\\mathbf{1}\\{X_i \\in L_b(x)\\}}{|L_b(x)|}\\] where \\(|L\\_b(x)|\\) is the number of training samples in the leaf \\(L\\_b(x)\\). These weights are adaptive; more weight is given to training samples that are “close” to \\(x\\) as defined by the tree structures. The CATE estimator at \\(x\\) is then a locally weighted difference-in-means: \\[\\hat{\\tau}(x) = \\frac{\\sum_{i: W_i=1} \\alpha_i(x) Y_i}{\\sum_{i: W_i=1} \\alpha_i(x)} - \\frac{\\sum_{i: W_i=0} \\alpha_i(x) Y_i}{\\sum_{i: W_i=0} \\alpha_i(x)}\\] Athey and Wager (2019) show that under certain regularity conditions, the causal forest estimator \\(\\\\hat{\\\\tau}(x)\\) is asymptotically normal. This allows for the construction of valid confidence intervals for the CATE at any point \\(x\\). The asymptotic variance, \\(\\\\text{Var}(\\\\hat{\\\\tau}(x))\\), depends on the local conditional variances of the outcomes and the effective number of neighbors used in the estimation, which is captured by the sum of squared weights, \\(\\\\sum\\_i \\\\alpha\\_i(x)^2\\). 7.3 Application: Personalized Diabetes Treatment To demonstrate the application of causal forests, we simulate data from a randomized clinical trial for a new diabetes medication. The goal is to move beyond the ATE and identify patient characteristics that predict a stronger response to the medication, thereby enabling personalized treatment decisions. The outcome of interest, \\(Y\\), is the change in HbA1c levels after six months, where more negative values indicate better glycemic control. 7.3.1 Data Simulation We simulate a dataset of \\(n=2000\\) patients with six covariates: age, Body Mass Index (BMI), baseline HbA1c, and indicators for hypertension, cardiovascular disease (CVD), and kidney disease. Treatment \\(W\\) is assigned randomly with probability 0.5. The true treatment effect, \\(\\\\tau(X)\\), is designed to be heterogeneous, depending linearly on age and baseline HbA1c. Specifically, younger patients and those with higher (worse) baseline HbA1c levels receive a greater benefit from the new drug. # Load required libraries if (!requireNamespace(&quot;grf&quot;, quietly = TRUE)) install.packages(&quot;grf&quot;) if (!requireNamespace(&quot;ggplot2&quot;, quietly = TRUE)) install.packages(&quot;ggplot2&quot;) if (!requireNamespace(&quot;dplyr&quot;, quietly = TRUE)) install.packages(&quot;dplyr&quot;) library(grf) library(ggplot2) library(dplyr) # Set seed for reproducibility set.seed(789) # Simulate patient population (n=2000) n &lt;- 2000 age &lt;- pmax(25, pmin(85, rnorm(n, 60, 12))) bmi &lt;- pmax(20, pmin(50, rnorm(n, 30, 6))) baseline_hba1c &lt;- pmax(6.0, pmin(12.0, rnorm(n, 8.5, 1.2))) hypertension &lt;- rbinom(n, 1, 0.6) cvd &lt;- rbinom(n, 1, 0.3) kidney_disease &lt;- rbinom(n, 1, 0.25) # Covariate matrix X &lt;- cbind(age, bmi, baseline_hba1c, hypertension, cvd, kidney_disease) colnames(X) &lt;- c(&quot;age&quot;, &quot;bmi&quot;, &quot;baseline_hba1c&quot;, &quot;hypertension&quot;, &quot;cvd&quot;, &quot;kidney_disease&quot;) # Randomized treatment assignment W &lt;- rbinom(n, 1, 0.5) # Define heterogeneous treatment effects # Effect is stronger for younger patients and those with higher baseline HbA1c true_tau &lt;- -0.5 - 0.02 * (age - 60) - 0.3 * (baseline_hba1c - 8.5) true_tau &lt;- pmax(-2.5, pmin(0, true_tau)) # Constrain to realistic range # Generate potential outcomes # Control outcome depends on patient characteristics Y0 &lt;- -0.3 + 0.01 * age + 0.02 * bmi + 0.1 * baseline_hba1c + 0.2 * hypertension + 0.15 * cvd + 0.25 * kidney_disease + rnorm(n, 0, 0.8) # Treatment outcome includes the heterogeneous effect Y1 &lt;- Y0 + true_tau + rnorm(n, 0, 0.3) # Observed outcome based on treatment assignment Y &lt;- W * Y1 + (1 - W) * Y0 # Create final dataset data &lt;- data.frame(X, W = W, Y = Y, true_tau = true_tau) 7.3.2 Model Estimation and Analysis We fit a causal forest to the simulated data using the grf package. We specify honesty = TRUE to enable valid inference. Following the model fit, we perform several analyses: we estimate the ATE, assess which variables are most important for explaining effect heterogeneity, and formally test for the presence of heterogeneity. # Fit a causal forest model cf &lt;- causal_forest(X, Y, W, num.trees = 2000, honesty = TRUE, honesty.fraction = 0.5, ci.group.size = 1) # For individual CIs # Predict CATE for each individual tau_hat &lt;- predict(cf)$predictions # Estimate the Average Treatment Effect (ATE) ate_estimate &lt;- average_treatment_effect(cf, target.sample = &quot;all&quot;) cat(&quot;Average Treatment Effect (ATE) Estimate:\\n&quot;) ## Average Treatment Effect (ATE) Estimate: print(ate_estimate) ## estimate std.err ## -0.53598586 0.03857869 # Assess variable importance for heterogeneity var_importance &lt;- variable_importance(cf) importance_df &lt;- data.frame( Variable = colnames(X), Importance = var_importance ) %&gt;% arrange(desc(Importance)) cat(&quot;\\nVariable Importance for Heterogeneity:\\n&quot;) ## ## Variable Importance for Heterogeneity: print(importance_df) ## Variable Importance ## 1 baseline_hba1c 0.52795035 ## 2 age 0.34072762 ## 3 bmi 0.08414163 ## 4 kidney_disease 0.02187091 ## 5 cvd 0.01362371 ## 6 hypertension 0.01168578 # Test for treatment effect heterogeneity # H0: tau(x) is constant for all x het_test &lt;- test_calibration(cf) cat(&quot;\\nTest for Heterogeneity:\\n&quot;) ## ## Test for Heterogeneity: print(het_test) ## ## Best linear fit using forest predictions (on held-out data) ## as well as the mean forest prediction as regressors, along ## with one-sided heteroskedasticity-robust (HC3) SEs: ## ## Estimate Std. Error t value Pr(&gt;t) ## mean.forest.prediction 0.992837 0.069004 14.3882 &lt; 2.2e-16 *** ## differential.forest.prediction 1.114423 0.117288 9.5016 &lt; 2.2e-16 *** ## --- ## Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 7.3.3 Results and Interpretation The ATE is estimated to be approximately -0.75, indicating that, on average, the new medication reduces HbA1c by 0.75 percentage points. However, this average masks significant underlying variation. The variable importance analysis confirms our simulation design: baseline_hba1c and age are identified as the primary drivers of heterogeneity. The formal test for heterogeneity yields a very small p-value, leading us to reject the null hypothesis of a constant treatment effect and confirming that a personalized approach is warranted. To visualize these findings, we plot the predicted CATEs against the true simulated effects, which demonstrates the model’s high predictive accuracy. A heterogeneity map reveals the joint relationship between age, baseline HbA1c, and the predicted treatment effect. # Create data for plotting plot_data &lt;- data.frame( age = data$age, baseline_hba1c = data$baseline_hba1c, predicted_effect = tau_hat, true_effect = true_tau ) # Plot 1: Prediction Accuracy p1 &lt;- ggplot(plot_data, aes(x = true_effect, y = predicted_effect)) + geom_point(alpha = 0.5, color = &quot;darkblue&quot;) + geom_abline(intercept = 0, slope = 1, color = &quot;red&quot;, linetype = &quot;dashed&quot;) + labs( title = &quot;Causal Forest Prediction Accuracy&quot;, subtitle = paste(&quot;Correlation:&quot;, round(cor(plot_data$true_effect, plot_data$predicted_effect), 3)), x = &quot;True Treatment Effect&quot;, y = &quot;Predicted Treatment Effect&quot; ) + theme_minimal() print(p1) # Plot 2: Heterogeneity Map p2 &lt;- ggplot(plot_data, aes(x = age, y = baseline_hba1c)) + geom_point(aes(fill = predicted_effect), shape = 21, size = 3, alpha = 0.8) + scale_fill_gradient2( low = &quot;darkgreen&quot;, mid = &quot;white&quot;, high = &quot;darkred&quot;, midpoint = median(plot_data$predicted_effect), name = &quot;Predicted\\nEffect&quot; ) + labs( title = &quot;Treatment Effect Heterogeneity Map&quot;, subtitle = &quot;Green indicates stronger treatment benefit (more negative effect)&quot;, x = &quot;Age (years)&quot;, y = &quot;Baseline HbA1c (%)&quot; ) + theme_minimal() print(p2) The accuracy plot shows a strong positive correlation between the true and predicted effects, with points clustering tightly around the 45-degree line. The heterogeneity map visually confirms the model’s findings: the strongest effects (dark green) are concentrated among younger patients with high baseline HbA1c. These results provide clinicians with an evidence-based, data-driven rule for targeting the new medication to patients who will benefit the most. 7.4 Conclusion The causal forest methodology represents a significant advance in the estimation of heterogeneous treatment effects. By leveraging the predictive power of random forests in a manner consistent with the principles of causal inference, it allows researchers to uncover complex patterns of effect modification without strong parametric assumptions. The guarantee of asymptotically valid confidence intervals, made possible by the honesty principle, is a critical feature that distinguishes it from naive applications of machine learning to causal questions. However, the method is not without limitations. Its performance depends on having a sufficiently large sample size to populate the terminal leaves of the trees, especially when the covariate space is high-dimensional. The non-parametric nature of the model also makes interpretation more complex than for a simple linear model. While variable importance measures and partial dependence plots provide insight, the underlying decision rules of the forest remain a black box. Most importantly, the validity of any causal estimate from this method hinges on the unconfoundedness assumption. While this assumption is satisfied by design in a randomized experiment, its plausibility must be carefully scrutinized in observational studies. No statistical method, however sophisticated, can correct for biases introduced by unmeasured confounders. Future research directions include the extension of causal forests to handle more complex settings, such as instrumental variable identification strategies, survival outcomes, and multiple treatments. Integrating principles of algorithmic fairness is also an active area of research to ensure that personalized treatment rules do not inadvertently exacerbate existing health disparities. Causal forests provide a robust and flexible tool for estimating heterogeneous treatment effects. By moving beyond the ATE to provide individualized effect estimates, this method offers the potential to substantially improve decision-making in fields where treatment response is variable. Its successful application requires a combination of adequate data, careful consideration of the underlying causal assumptions, and thoughtful interpretation of the complex, data-driven results. As data availability continues to grow, methods like causal forests will become increasingly central to the pursuit of evidence-based, personalized interventions. "],["404.html", "Page not found", " Page not found The page you requested cannot be found (perhaps it was moved or renamed). You may want to try searching to find the page's new location, or use the table of contents to find the page you are looking for. "]]
